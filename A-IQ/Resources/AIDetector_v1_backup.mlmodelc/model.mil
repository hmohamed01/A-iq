program(1.0)
[buildInfo = dict<tensor<string, []>, tensor<string, []>>({{"coremlc-component-MIL", "3500.14.1"}, {"coremlc-version", "3500.32.1"}, {"coremltools-component-torch", "2.9.1"}, {"coremltools-source-dialect", "TorchScript"}, {"coremltools-version", "9.0"}})]
{
    func main<ios17>(tensor<fp32, [1, 3, 224, 224]> image) {
            tensor<fp32, []> image__scaled___y_0 = const()[name = tensor<string, []>("image__scaled___y_0"), val = tensor<fp32, []>(0x1.010102p-8)];
            tensor<fp32, [1, 3, 224, 224]> image__scaled__ = mul(x = image, y = image__scaled___y_0)[name = tensor<string, []>("image__scaled__")];
            tensor<fp32, [1, 3, 1, 1]> image__biased___y_0 = const()[name = tensor<string, []>("image__biased___y_0"), val = tensor<fp32, [1, 3, 1, 1]>([[[[-0x1p-1]], [[-0x1p-1]], [[-0x1p-1]]]])];
            tensor<fp32, [1, 3, 224, 224]> image__biased__ = add(x = image__scaled__, y = image__biased___y_0)[name = tensor<string, []>("image__biased__")];
            tensor<int32, []> var_7 = const()[name = tensor<string, []>("op_7"), val = tensor<int32, []>(1)];
            tensor<string, []> var_35_pad_type_0 = const()[name = tensor<string, []>("op_35_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [2]> var_35_strides_0 = const()[name = tensor<string, []>("op_35_strides_0"), val = tensor<int32, [2]>([16, 16])];
            tensor<int32, [4]> var_35_pad_0 = const()[name = tensor<string, []>("op_35_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<int32, [2]> var_35_dilations_0 = const()[name = tensor<string, []>("op_35_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> var_35_groups_0 = const()[name = tensor<string, []>("op_35_groups_0"), val = tensor<int32, []>(1)];
            tensor<string, []> image_to_fp16_dtype_0 = const()[name = tensor<string, []>("image_to_fp16_dtype_0"), val = tensor<string, []>("fp16")];
            tensor<fp16, [768, 3, 16, 16]> model_vit_embeddings_patch_embeddings_projection_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_embeddings_patch_embeddings_projection_weight_to_fp16"), val = tensor<fp16, [768, 3, 16, 16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(64)))];
            tensor<fp16, [768]> model_vit_embeddings_patch_embeddings_projection_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_embeddings_patch_embeddings_projection_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1179776)))];
            tensor<fp16, [1, 3, 224, 224]> image_to_fp16 = cast(dtype = image_to_fp16_dtype_0, x = image__biased__)[name = tensor<string, []>("cast_50")];
            tensor<fp16, [1, 768, 14, 14]> var_35_cast_fp16 = conv(bias = model_vit_embeddings_patch_embeddings_projection_bias_to_fp16, dilations = var_35_dilations_0, groups = var_35_groups_0, pad = var_35_pad_0, pad_type = var_35_pad_type_0, strides = var_35_strides_0, weight = model_vit_embeddings_patch_embeddings_projection_weight_to_fp16, x = image_to_fp16)[name = tensor<string, []>("op_35_cast_fp16")];
            tensor<int32, [3]> concat_0 = const()[name = tensor<string, []>("concat_0"), val = tensor<int32, [3]>([1, 768, 196])];
            tensor<fp16, [1, 768, 196]> var_36_cast_fp16 = reshape(shape = concat_0, x = var_35_cast_fp16)[name = tensor<string, []>("op_36_cast_fp16")];
            tensor<int32, [3]> embeddings_1_perm_0 = const()[name = tensor<string, []>("embeddings_1_perm_0"), val = tensor<int32, [3]>([0, 2, 1])];
            tensor<bool, []> embeddings_3_interleave_0 = const()[name = tensor<string, []>("embeddings_3_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 1, 768]> model_vit_embeddings_cls_token_to_fp16 = const()[name = tensor<string, []>("model_vit_embeddings_cls_token_to_fp16"), val = tensor<fp16, [1, 1, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1181376)))];
            tensor<fp16, [1, 196, 768]> embeddings_1_cast_fp16 = transpose(perm = embeddings_1_perm_0, x = var_36_cast_fp16)[name = tensor<string, []>("transpose_120")];
            tensor<fp16, [1, 197, 768]> embeddings_3_cast_fp16 = concat(axis = var_7, interleave = embeddings_3_interleave_0, values = (model_vit_embeddings_cls_token_to_fp16, embeddings_1_cast_fp16))[name = tensor<string, []>("embeddings_3_cast_fp16")];
            tensor<fp16, [1, 197, 768]> model_vit_embeddings_position_embeddings_to_fp16 = const()[name = tensor<string, []>("model_vit_embeddings_position_embeddings_to_fp16"), val = tensor<fp16, [1, 197, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1182976)))];
            tensor<fp16, [1, 197, 768]> input_1_cast_fp16 = add(x = embeddings_3_cast_fp16, y = model_vit_embeddings_position_embeddings_to_fp16)[name = tensor<string, []>("input_1_cast_fp16")];
            tensor<int32, [1]> hidden_states_1_axes_0 = const()[name = tensor<string, []>("hidden_states_1_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_0_layernorm_before_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_0_layernorm_before_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1485632)))];
            tensor<fp16, [768]> model_vit_encoder_layer_0_layernorm_before_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_0_layernorm_before_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1487232)))];
            tensor<fp16, []> var_12_to_fp16 = const()[name = tensor<string, []>("op_12_to_fp16"), val = tensor<fp16, []>(0x1p-24)];
            tensor<fp16, [1, 197, 768]> hidden_states_1_cast_fp16 = layer_norm(axes = hidden_states_1_axes_0, beta = model_vit_encoder_layer_0_layernorm_before_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_0_layernorm_before_weight_to_fp16, x = input_1_cast_fp16)[name = tensor<string, []>("hidden_states_1_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_0_attention_attention_key_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_0_attention_attention_key_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1488832)))];
            tensor<fp16, [768]> model_vit_encoder_layer_0_attention_attention_key_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_0_attention_attention_key_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(2668544)))];
            tensor<fp16, [1, 197, 768]> linear_0_cast_fp16 = linear(bias = model_vit_encoder_layer_0_attention_attention_key_bias_to_fp16, weight = model_vit_encoder_layer_0_attention_attention_key_weight_to_fp16, x = hidden_states_1_cast_fp16)[name = tensor<string, []>("linear_0_cast_fp16")];
            tensor<int32, [4]> var_86 = const()[name = tensor<string, []>("op_86"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_87_cast_fp16 = reshape(shape = var_86, x = linear_0_cast_fp16)[name = tensor<string, []>("op_87_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_0_attention_attention_value_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_0_attention_attention_value_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(2670144)))];
            tensor<fp16, [768]> model_vit_encoder_layer_0_attention_attention_value_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_0_attention_attention_value_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(3849856)))];
            tensor<fp16, [1, 197, 768]> linear_1_cast_fp16 = linear(bias = model_vit_encoder_layer_0_attention_attention_value_bias_to_fp16, weight = model_vit_encoder_layer_0_attention_attention_value_weight_to_fp16, x = hidden_states_1_cast_fp16)[name = tensor<string, []>("linear_1_cast_fp16")];
            tensor<int32, [4]> var_92 = const()[name = tensor<string, []>("op_92"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_93_cast_fp16 = reshape(shape = var_92, x = linear_1_cast_fp16)[name = tensor<string, []>("op_93_cast_fp16")];
            tensor<int32, [4]> value_1_perm_0 = const()[name = tensor<string, []>("value_1_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_0_attention_attention_query_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_0_attention_attention_query_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(3851456)))];
            tensor<fp16, [768]> model_vit_encoder_layer_0_attention_attention_query_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_0_attention_attention_query_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(5031168)))];
            tensor<fp16, [1, 197, 768]> linear_2_cast_fp16 = linear(bias = model_vit_encoder_layer_0_attention_attention_query_bias_to_fp16, weight = model_vit_encoder_layer_0_attention_attention_query_weight_to_fp16, x = hidden_states_1_cast_fp16)[name = tensor<string, []>("linear_2_cast_fp16")];
            tensor<int32, [4]> var_98 = const()[name = tensor<string, []>("op_98"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_99_cast_fp16 = reshape(shape = var_98, x = linear_2_cast_fp16)[name = tensor<string, []>("op_99_cast_fp16")];
            tensor<fp16, []> var_17_to_fp16 = const()[name = tensor<string, []>("op_17_to_fp16"), val = tensor<fp16, []>(0x1p-3)];
            tensor<fp16, [1, 197, 12, 64]> mul_0_cast_fp16 = mul(x = var_99_cast_fp16, y = var_17_to_fp16)[name = tensor<string, []>("mul_0_cast_fp16")];
            tensor<bool, []> matmul_0_transpose_y_0 = const()[name = tensor<string, []>("matmul_0_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_0_transpose_x_0 = const()[name = tensor<string, []>("matmul_0_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_48_perm_0 = const()[name = tensor<string, []>("transpose_48_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_49_perm_0 = const()[name = tensor<string, []>("transpose_49_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp16, [1, 12, 197, 64]> transpose_49 = transpose(perm = transpose_49_perm_0, x = var_87_cast_fp16)[name = tensor<string, []>("transpose_117")];
            tensor<fp16, [1, 12, 197, 64]> transpose_48 = transpose(perm = transpose_48_perm_0, x = mul_0_cast_fp16)[name = tensor<string, []>("transpose_118")];
            tensor<fp16, [1, 12, 197, 197]> matmul_0_cast_fp16 = matmul(transpose_x = matmul_0_transpose_x_0, transpose_y = matmul_0_transpose_y_0, x = transpose_48, y = transpose_49)[name = tensor<string, []>("matmul_0_cast_fp16")];
            tensor<int32, []> softmax_0_axis_0 = const()[name = tensor<string, []>("softmax_0_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp16, [1, 12, 197, 197]> softmax_0_cast_fp16 = softmax(axis = softmax_0_axis_0, x = matmul_0_cast_fp16)[name = tensor<string, []>("softmax_0_cast_fp16")];
            tensor<bool, []> attn_output_1_transpose_x_0 = const()[name = tensor<string, []>("attn_output_1_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_1_transpose_y_0 = const()[name = tensor<string, []>("attn_output_1_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 12, 197, 64]> value_1_cast_fp16 = transpose(perm = value_1_perm_0, x = var_93_cast_fp16)[name = tensor<string, []>("transpose_119")];
            tensor<fp16, [1, 12, 197, 64]> attn_output_1_cast_fp16 = matmul(transpose_x = attn_output_1_transpose_x_0, transpose_y = attn_output_1_transpose_y_0, x = softmax_0_cast_fp16, y = value_1_cast_fp16)[name = tensor<string, []>("attn_output_1_cast_fp16")];
            tensor<int32, [4]> var_102_perm_0 = const()[name = tensor<string, []>("op_102_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_106 = const()[name = tensor<string, []>("op_106"), val = tensor<int32, [3]>([1, 197, 768])];
            tensor<fp16, [1, 197, 12, 64]> var_102_cast_fp16 = transpose(perm = var_102_perm_0, x = attn_output_1_cast_fp16)[name = tensor<string, []>("transpose_116")];
            tensor<fp16, [1, 197, 768]> input_5_cast_fp16 = reshape(shape = var_106, x = var_102_cast_fp16)[name = tensor<string, []>("input_5_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_0_attention_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_0_attention_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(5032768)))];
            tensor<fp16, [768]> model_vit_encoder_layer_0_attention_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_0_attention_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(6212480)))];
            tensor<fp16, [1, 197, 768]> linear_3_cast_fp16 = linear(bias = model_vit_encoder_layer_0_attention_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_0_attention_output_dense_weight_to_fp16, x = input_5_cast_fp16)[name = tensor<string, []>("linear_3_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_9_cast_fp16 = add(x = linear_3_cast_fp16, y = input_1_cast_fp16)[name = tensor<string, []>("input_9_cast_fp16")];
            tensor<int32, [1]> input_11_axes_0 = const()[name = tensor<string, []>("input_11_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_0_layernorm_after_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_0_layernorm_after_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(6214080)))];
            tensor<fp16, [768]> model_vit_encoder_layer_0_layernorm_after_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_0_layernorm_after_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(6215680)))];
            tensor<fp16, [1, 197, 768]> input_11_cast_fp16 = layer_norm(axes = input_11_axes_0, beta = model_vit_encoder_layer_0_layernorm_after_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_0_layernorm_after_weight_to_fp16, x = input_9_cast_fp16)[name = tensor<string, []>("input_11_cast_fp16")];
            tensor<fp16, [3072, 768]> model_vit_encoder_layer_0_intermediate_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_0_intermediate_dense_weight_to_fp16"), val = tensor<fp16, [3072, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(6217280)))];
            tensor<fp16, [3072]> model_vit_encoder_layer_0_intermediate_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_0_intermediate_dense_bias_to_fp16"), val = tensor<fp16, [3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(10935936)))];
            tensor<fp16, [1, 197, 3072]> linear_4_cast_fp16 = linear(bias = model_vit_encoder_layer_0_intermediate_dense_bias_to_fp16, weight = model_vit_encoder_layer_0_intermediate_dense_weight_to_fp16, x = input_11_cast_fp16)[name = tensor<string, []>("linear_4_cast_fp16")];
            tensor<string, []> input_15_mode_0 = const()[name = tensor<string, []>("input_15_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 197, 3072]> input_15_cast_fp16 = gelu(mode = input_15_mode_0, x = linear_4_cast_fp16)[name = tensor<string, []>("input_15_cast_fp16")];
            tensor<fp16, [768, 3072]> model_vit_encoder_layer_0_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_0_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(10942144)))];
            tensor<fp16, [768]> model_vit_encoder_layer_0_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_0_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(15660800)))];
            tensor<fp16, [1, 197, 768]> linear_5_cast_fp16 = linear(bias = model_vit_encoder_layer_0_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_0_output_dense_weight_to_fp16, x = input_15_cast_fp16)[name = tensor<string, []>("linear_5_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_19_cast_fp16 = add(x = linear_5_cast_fp16, y = input_9_cast_fp16)[name = tensor<string, []>("input_19_cast_fp16")];
            tensor<int32, [1]> hidden_states_5_axes_0 = const()[name = tensor<string, []>("hidden_states_5_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_1_layernorm_before_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_1_layernorm_before_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(15662400)))];
            tensor<fp16, [768]> model_vit_encoder_layer_1_layernorm_before_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_1_layernorm_before_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(15664000)))];
            tensor<fp16, [1, 197, 768]> hidden_states_5_cast_fp16 = layer_norm(axes = hidden_states_5_axes_0, beta = model_vit_encoder_layer_1_layernorm_before_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_1_layernorm_before_weight_to_fp16, x = input_19_cast_fp16)[name = tensor<string, []>("hidden_states_5_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_1_attention_attention_key_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_1_attention_attention_key_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(15665600)))];
            tensor<fp16, [768]> model_vit_encoder_layer_1_attention_attention_key_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_1_attention_attention_key_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(16845312)))];
            tensor<fp16, [1, 197, 768]> linear_6_cast_fp16 = linear(bias = model_vit_encoder_layer_1_attention_attention_key_bias_to_fp16, weight = model_vit_encoder_layer_1_attention_attention_key_weight_to_fp16, x = hidden_states_5_cast_fp16)[name = tensor<string, []>("linear_6_cast_fp16")];
            tensor<int32, [4]> var_147 = const()[name = tensor<string, []>("op_147"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_148_cast_fp16 = reshape(shape = var_147, x = linear_6_cast_fp16)[name = tensor<string, []>("op_148_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_1_attention_attention_value_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_1_attention_attention_value_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(16846912)))];
            tensor<fp16, [768]> model_vit_encoder_layer_1_attention_attention_value_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_1_attention_attention_value_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(18026624)))];
            tensor<fp16, [1, 197, 768]> linear_7_cast_fp16 = linear(bias = model_vit_encoder_layer_1_attention_attention_value_bias_to_fp16, weight = model_vit_encoder_layer_1_attention_attention_value_weight_to_fp16, x = hidden_states_5_cast_fp16)[name = tensor<string, []>("linear_7_cast_fp16")];
            tensor<int32, [4]> var_153 = const()[name = tensor<string, []>("op_153"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_154_cast_fp16 = reshape(shape = var_153, x = linear_7_cast_fp16)[name = tensor<string, []>("op_154_cast_fp16")];
            tensor<int32, [4]> value_3_perm_0 = const()[name = tensor<string, []>("value_3_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_1_attention_attention_query_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_1_attention_attention_query_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(18028224)))];
            tensor<fp16, [768]> model_vit_encoder_layer_1_attention_attention_query_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_1_attention_attention_query_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(19207936)))];
            tensor<fp16, [1, 197, 768]> linear_8_cast_fp16 = linear(bias = model_vit_encoder_layer_1_attention_attention_query_bias_to_fp16, weight = model_vit_encoder_layer_1_attention_attention_query_weight_to_fp16, x = hidden_states_5_cast_fp16)[name = tensor<string, []>("linear_8_cast_fp16")];
            tensor<int32, [4]> var_159 = const()[name = tensor<string, []>("op_159"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_160_cast_fp16 = reshape(shape = var_159, x = linear_8_cast_fp16)[name = tensor<string, []>("op_160_cast_fp16")];
            tensor<fp16, [1, 197, 12, 64]> mul_1_cast_fp16 = mul(x = var_160_cast_fp16, y = var_17_to_fp16)[name = tensor<string, []>("mul_1_cast_fp16")];
            tensor<bool, []> matmul_1_transpose_y_0 = const()[name = tensor<string, []>("matmul_1_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_1_transpose_x_0 = const()[name = tensor<string, []>("matmul_1_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_50_perm_0 = const()[name = tensor<string, []>("transpose_50_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_51_perm_0 = const()[name = tensor<string, []>("transpose_51_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp16, [1, 12, 197, 64]> transpose_51 = transpose(perm = transpose_51_perm_0, x = var_148_cast_fp16)[name = tensor<string, []>("transpose_113")];
            tensor<fp16, [1, 12, 197, 64]> transpose_50 = transpose(perm = transpose_50_perm_0, x = mul_1_cast_fp16)[name = tensor<string, []>("transpose_114")];
            tensor<fp16, [1, 12, 197, 197]> matmul_1_cast_fp16 = matmul(transpose_x = matmul_1_transpose_x_0, transpose_y = matmul_1_transpose_y_0, x = transpose_50, y = transpose_51)[name = tensor<string, []>("matmul_1_cast_fp16")];
            tensor<int32, []> softmax_1_axis_0 = const()[name = tensor<string, []>("softmax_1_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp16, [1, 12, 197, 197]> softmax_1_cast_fp16 = softmax(axis = softmax_1_axis_0, x = matmul_1_cast_fp16)[name = tensor<string, []>("softmax_1_cast_fp16")];
            tensor<bool, []> attn_output_3_transpose_x_0 = const()[name = tensor<string, []>("attn_output_3_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_3_transpose_y_0 = const()[name = tensor<string, []>("attn_output_3_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 12, 197, 64]> value_3_cast_fp16 = transpose(perm = value_3_perm_0, x = var_154_cast_fp16)[name = tensor<string, []>("transpose_115")];
            tensor<fp16, [1, 12, 197, 64]> attn_output_3_cast_fp16 = matmul(transpose_x = attn_output_3_transpose_x_0, transpose_y = attn_output_3_transpose_y_0, x = softmax_1_cast_fp16, y = value_3_cast_fp16)[name = tensor<string, []>("attn_output_3_cast_fp16")];
            tensor<int32, [4]> var_163_perm_0 = const()[name = tensor<string, []>("op_163_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_167 = const()[name = tensor<string, []>("op_167"), val = tensor<int32, [3]>([1, 197, 768])];
            tensor<fp16, [1, 197, 12, 64]> var_163_cast_fp16 = transpose(perm = var_163_perm_0, x = attn_output_3_cast_fp16)[name = tensor<string, []>("transpose_112")];
            tensor<fp16, [1, 197, 768]> input_21_cast_fp16 = reshape(shape = var_167, x = var_163_cast_fp16)[name = tensor<string, []>("input_21_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_1_attention_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_1_attention_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(19209536)))];
            tensor<fp16, [768]> model_vit_encoder_layer_1_attention_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_1_attention_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(20389248)))];
            tensor<fp16, [1, 197, 768]> linear_9_cast_fp16 = linear(bias = model_vit_encoder_layer_1_attention_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_1_attention_output_dense_weight_to_fp16, x = input_21_cast_fp16)[name = tensor<string, []>("linear_9_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_25_cast_fp16 = add(x = linear_9_cast_fp16, y = input_19_cast_fp16)[name = tensor<string, []>("input_25_cast_fp16")];
            tensor<int32, [1]> input_27_axes_0 = const()[name = tensor<string, []>("input_27_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_1_layernorm_after_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_1_layernorm_after_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(20390848)))];
            tensor<fp16, [768]> model_vit_encoder_layer_1_layernorm_after_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_1_layernorm_after_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(20392448)))];
            tensor<fp16, [1, 197, 768]> input_27_cast_fp16 = layer_norm(axes = input_27_axes_0, beta = model_vit_encoder_layer_1_layernorm_after_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_1_layernorm_after_weight_to_fp16, x = input_25_cast_fp16)[name = tensor<string, []>("input_27_cast_fp16")];
            tensor<fp16, [3072, 768]> model_vit_encoder_layer_1_intermediate_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_1_intermediate_dense_weight_to_fp16"), val = tensor<fp16, [3072, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(20394048)))];
            tensor<fp16, [3072]> model_vit_encoder_layer_1_intermediate_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_1_intermediate_dense_bias_to_fp16"), val = tensor<fp16, [3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(25112704)))];
            tensor<fp16, [1, 197, 3072]> linear_10_cast_fp16 = linear(bias = model_vit_encoder_layer_1_intermediate_dense_bias_to_fp16, weight = model_vit_encoder_layer_1_intermediate_dense_weight_to_fp16, x = input_27_cast_fp16)[name = tensor<string, []>("linear_10_cast_fp16")];
            tensor<string, []> input_31_mode_0 = const()[name = tensor<string, []>("input_31_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 197, 3072]> input_31_cast_fp16 = gelu(mode = input_31_mode_0, x = linear_10_cast_fp16)[name = tensor<string, []>("input_31_cast_fp16")];
            tensor<fp16, [768, 3072]> model_vit_encoder_layer_1_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_1_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(25118912)))];
            tensor<fp16, [768]> model_vit_encoder_layer_1_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_1_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(29837568)))];
            tensor<fp16, [1, 197, 768]> linear_11_cast_fp16 = linear(bias = model_vit_encoder_layer_1_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_1_output_dense_weight_to_fp16, x = input_31_cast_fp16)[name = tensor<string, []>("linear_11_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_35_cast_fp16 = add(x = linear_11_cast_fp16, y = input_25_cast_fp16)[name = tensor<string, []>("input_35_cast_fp16")];
            tensor<int32, [1]> hidden_states_9_axes_0 = const()[name = tensor<string, []>("hidden_states_9_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_2_layernorm_before_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_2_layernorm_before_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(29839168)))];
            tensor<fp16, [768]> model_vit_encoder_layer_2_layernorm_before_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_2_layernorm_before_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(29840768)))];
            tensor<fp16, [1, 197, 768]> hidden_states_9_cast_fp16 = layer_norm(axes = hidden_states_9_axes_0, beta = model_vit_encoder_layer_2_layernorm_before_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_2_layernorm_before_weight_to_fp16, x = input_35_cast_fp16)[name = tensor<string, []>("hidden_states_9_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_2_attention_attention_key_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_2_attention_attention_key_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(29842368)))];
            tensor<fp16, [768]> model_vit_encoder_layer_2_attention_attention_key_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_2_attention_attention_key_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(31022080)))];
            tensor<fp16, [1, 197, 768]> linear_12_cast_fp16 = linear(bias = model_vit_encoder_layer_2_attention_attention_key_bias_to_fp16, weight = model_vit_encoder_layer_2_attention_attention_key_weight_to_fp16, x = hidden_states_9_cast_fp16)[name = tensor<string, []>("linear_12_cast_fp16")];
            tensor<int32, [4]> var_208 = const()[name = tensor<string, []>("op_208"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_209_cast_fp16 = reshape(shape = var_208, x = linear_12_cast_fp16)[name = tensor<string, []>("op_209_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_2_attention_attention_value_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_2_attention_attention_value_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(31023680)))];
            tensor<fp16, [768]> model_vit_encoder_layer_2_attention_attention_value_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_2_attention_attention_value_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(32203392)))];
            tensor<fp16, [1, 197, 768]> linear_13_cast_fp16 = linear(bias = model_vit_encoder_layer_2_attention_attention_value_bias_to_fp16, weight = model_vit_encoder_layer_2_attention_attention_value_weight_to_fp16, x = hidden_states_9_cast_fp16)[name = tensor<string, []>("linear_13_cast_fp16")];
            tensor<int32, [4]> var_214 = const()[name = tensor<string, []>("op_214"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_215_cast_fp16 = reshape(shape = var_214, x = linear_13_cast_fp16)[name = tensor<string, []>("op_215_cast_fp16")];
            tensor<int32, [4]> value_5_perm_0 = const()[name = tensor<string, []>("value_5_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_2_attention_attention_query_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_2_attention_attention_query_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(32204992)))];
            tensor<fp16, [768]> model_vit_encoder_layer_2_attention_attention_query_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_2_attention_attention_query_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(33384704)))];
            tensor<fp16, [1, 197, 768]> linear_14_cast_fp16 = linear(bias = model_vit_encoder_layer_2_attention_attention_query_bias_to_fp16, weight = model_vit_encoder_layer_2_attention_attention_query_weight_to_fp16, x = hidden_states_9_cast_fp16)[name = tensor<string, []>("linear_14_cast_fp16")];
            tensor<int32, [4]> var_220 = const()[name = tensor<string, []>("op_220"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_221_cast_fp16 = reshape(shape = var_220, x = linear_14_cast_fp16)[name = tensor<string, []>("op_221_cast_fp16")];
            tensor<fp16, [1, 197, 12, 64]> mul_2_cast_fp16 = mul(x = var_221_cast_fp16, y = var_17_to_fp16)[name = tensor<string, []>("mul_2_cast_fp16")];
            tensor<bool, []> matmul_2_transpose_y_0 = const()[name = tensor<string, []>("matmul_2_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_2_transpose_x_0 = const()[name = tensor<string, []>("matmul_2_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_52_perm_0 = const()[name = tensor<string, []>("transpose_52_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_53_perm_0 = const()[name = tensor<string, []>("transpose_53_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp16, [1, 12, 197, 64]> transpose_53 = transpose(perm = transpose_53_perm_0, x = var_209_cast_fp16)[name = tensor<string, []>("transpose_109")];
            tensor<fp16, [1, 12, 197, 64]> transpose_52 = transpose(perm = transpose_52_perm_0, x = mul_2_cast_fp16)[name = tensor<string, []>("transpose_110")];
            tensor<fp16, [1, 12, 197, 197]> matmul_2_cast_fp16 = matmul(transpose_x = matmul_2_transpose_x_0, transpose_y = matmul_2_transpose_y_0, x = transpose_52, y = transpose_53)[name = tensor<string, []>("matmul_2_cast_fp16")];
            tensor<int32, []> softmax_2_axis_0 = const()[name = tensor<string, []>("softmax_2_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp16, [1, 12, 197, 197]> softmax_2_cast_fp16 = softmax(axis = softmax_2_axis_0, x = matmul_2_cast_fp16)[name = tensor<string, []>("softmax_2_cast_fp16")];
            tensor<bool, []> attn_output_5_transpose_x_0 = const()[name = tensor<string, []>("attn_output_5_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_5_transpose_y_0 = const()[name = tensor<string, []>("attn_output_5_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 12, 197, 64]> value_5_cast_fp16 = transpose(perm = value_5_perm_0, x = var_215_cast_fp16)[name = tensor<string, []>("transpose_111")];
            tensor<fp16, [1, 12, 197, 64]> attn_output_5_cast_fp16 = matmul(transpose_x = attn_output_5_transpose_x_0, transpose_y = attn_output_5_transpose_y_0, x = softmax_2_cast_fp16, y = value_5_cast_fp16)[name = tensor<string, []>("attn_output_5_cast_fp16")];
            tensor<int32, [4]> var_224_perm_0 = const()[name = tensor<string, []>("op_224_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_228 = const()[name = tensor<string, []>("op_228"), val = tensor<int32, [3]>([1, 197, 768])];
            tensor<fp16, [1, 197, 12, 64]> var_224_cast_fp16 = transpose(perm = var_224_perm_0, x = attn_output_5_cast_fp16)[name = tensor<string, []>("transpose_108")];
            tensor<fp16, [1, 197, 768]> input_37_cast_fp16 = reshape(shape = var_228, x = var_224_cast_fp16)[name = tensor<string, []>("input_37_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_2_attention_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_2_attention_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(33386304)))];
            tensor<fp16, [768]> model_vit_encoder_layer_2_attention_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_2_attention_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(34566016)))];
            tensor<fp16, [1, 197, 768]> linear_15_cast_fp16 = linear(bias = model_vit_encoder_layer_2_attention_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_2_attention_output_dense_weight_to_fp16, x = input_37_cast_fp16)[name = tensor<string, []>("linear_15_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_41_cast_fp16 = add(x = linear_15_cast_fp16, y = input_35_cast_fp16)[name = tensor<string, []>("input_41_cast_fp16")];
            tensor<int32, [1]> input_43_axes_0 = const()[name = tensor<string, []>("input_43_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_2_layernorm_after_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_2_layernorm_after_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(34567616)))];
            tensor<fp16, [768]> model_vit_encoder_layer_2_layernorm_after_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_2_layernorm_after_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(34569216)))];
            tensor<fp16, [1, 197, 768]> input_43_cast_fp16 = layer_norm(axes = input_43_axes_0, beta = model_vit_encoder_layer_2_layernorm_after_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_2_layernorm_after_weight_to_fp16, x = input_41_cast_fp16)[name = tensor<string, []>("input_43_cast_fp16")];
            tensor<fp16, [3072, 768]> model_vit_encoder_layer_2_intermediate_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_2_intermediate_dense_weight_to_fp16"), val = tensor<fp16, [3072, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(34570816)))];
            tensor<fp16, [3072]> model_vit_encoder_layer_2_intermediate_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_2_intermediate_dense_bias_to_fp16"), val = tensor<fp16, [3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(39289472)))];
            tensor<fp16, [1, 197, 3072]> linear_16_cast_fp16 = linear(bias = model_vit_encoder_layer_2_intermediate_dense_bias_to_fp16, weight = model_vit_encoder_layer_2_intermediate_dense_weight_to_fp16, x = input_43_cast_fp16)[name = tensor<string, []>("linear_16_cast_fp16")];
            tensor<string, []> input_47_mode_0 = const()[name = tensor<string, []>("input_47_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 197, 3072]> input_47_cast_fp16 = gelu(mode = input_47_mode_0, x = linear_16_cast_fp16)[name = tensor<string, []>("input_47_cast_fp16")];
            tensor<fp16, [768, 3072]> model_vit_encoder_layer_2_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_2_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(39295680)))];
            tensor<fp16, [768]> model_vit_encoder_layer_2_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_2_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(44014336)))];
            tensor<fp16, [1, 197, 768]> linear_17_cast_fp16 = linear(bias = model_vit_encoder_layer_2_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_2_output_dense_weight_to_fp16, x = input_47_cast_fp16)[name = tensor<string, []>("linear_17_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_51_cast_fp16 = add(x = linear_17_cast_fp16, y = input_41_cast_fp16)[name = tensor<string, []>("input_51_cast_fp16")];
            tensor<int32, [1]> hidden_states_13_axes_0 = const()[name = tensor<string, []>("hidden_states_13_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_3_layernorm_before_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_3_layernorm_before_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(44015936)))];
            tensor<fp16, [768]> model_vit_encoder_layer_3_layernorm_before_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_3_layernorm_before_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(44017536)))];
            tensor<fp16, [1, 197, 768]> hidden_states_13_cast_fp16 = layer_norm(axes = hidden_states_13_axes_0, beta = model_vit_encoder_layer_3_layernorm_before_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_3_layernorm_before_weight_to_fp16, x = input_51_cast_fp16)[name = tensor<string, []>("hidden_states_13_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_3_attention_attention_key_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_3_attention_attention_key_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(44019136)))];
            tensor<fp16, [768]> model_vit_encoder_layer_3_attention_attention_key_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_3_attention_attention_key_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(45198848)))];
            tensor<fp16, [1, 197, 768]> linear_18_cast_fp16 = linear(bias = model_vit_encoder_layer_3_attention_attention_key_bias_to_fp16, weight = model_vit_encoder_layer_3_attention_attention_key_weight_to_fp16, x = hidden_states_13_cast_fp16)[name = tensor<string, []>("linear_18_cast_fp16")];
            tensor<int32, [4]> var_269 = const()[name = tensor<string, []>("op_269"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_270_cast_fp16 = reshape(shape = var_269, x = linear_18_cast_fp16)[name = tensor<string, []>("op_270_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_3_attention_attention_value_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_3_attention_attention_value_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(45200448)))];
            tensor<fp16, [768]> model_vit_encoder_layer_3_attention_attention_value_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_3_attention_attention_value_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(46380160)))];
            tensor<fp16, [1, 197, 768]> linear_19_cast_fp16 = linear(bias = model_vit_encoder_layer_3_attention_attention_value_bias_to_fp16, weight = model_vit_encoder_layer_3_attention_attention_value_weight_to_fp16, x = hidden_states_13_cast_fp16)[name = tensor<string, []>("linear_19_cast_fp16")];
            tensor<int32, [4]> var_275 = const()[name = tensor<string, []>("op_275"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_276_cast_fp16 = reshape(shape = var_275, x = linear_19_cast_fp16)[name = tensor<string, []>("op_276_cast_fp16")];
            tensor<int32, [4]> value_7_perm_0 = const()[name = tensor<string, []>("value_7_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_3_attention_attention_query_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_3_attention_attention_query_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(46381760)))];
            tensor<fp16, [768]> model_vit_encoder_layer_3_attention_attention_query_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_3_attention_attention_query_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(47561472)))];
            tensor<fp16, [1, 197, 768]> linear_20_cast_fp16 = linear(bias = model_vit_encoder_layer_3_attention_attention_query_bias_to_fp16, weight = model_vit_encoder_layer_3_attention_attention_query_weight_to_fp16, x = hidden_states_13_cast_fp16)[name = tensor<string, []>("linear_20_cast_fp16")];
            tensor<int32, [4]> var_281 = const()[name = tensor<string, []>("op_281"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_282_cast_fp16 = reshape(shape = var_281, x = linear_20_cast_fp16)[name = tensor<string, []>("op_282_cast_fp16")];
            tensor<fp16, [1, 197, 12, 64]> mul_3_cast_fp16 = mul(x = var_282_cast_fp16, y = var_17_to_fp16)[name = tensor<string, []>("mul_3_cast_fp16")];
            tensor<bool, []> matmul_3_transpose_y_0 = const()[name = tensor<string, []>("matmul_3_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_3_transpose_x_0 = const()[name = tensor<string, []>("matmul_3_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_54_perm_0 = const()[name = tensor<string, []>("transpose_54_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_55_perm_0 = const()[name = tensor<string, []>("transpose_55_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp16, [1, 12, 197, 64]> transpose_55 = transpose(perm = transpose_55_perm_0, x = var_270_cast_fp16)[name = tensor<string, []>("transpose_105")];
            tensor<fp16, [1, 12, 197, 64]> transpose_54 = transpose(perm = transpose_54_perm_0, x = mul_3_cast_fp16)[name = tensor<string, []>("transpose_106")];
            tensor<fp16, [1, 12, 197, 197]> matmul_3_cast_fp16 = matmul(transpose_x = matmul_3_transpose_x_0, transpose_y = matmul_3_transpose_y_0, x = transpose_54, y = transpose_55)[name = tensor<string, []>("matmul_3_cast_fp16")];
            tensor<int32, []> softmax_3_axis_0 = const()[name = tensor<string, []>("softmax_3_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp16, [1, 12, 197, 197]> softmax_3_cast_fp16 = softmax(axis = softmax_3_axis_0, x = matmul_3_cast_fp16)[name = tensor<string, []>("softmax_3_cast_fp16")];
            tensor<bool, []> attn_output_7_transpose_x_0 = const()[name = tensor<string, []>("attn_output_7_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_7_transpose_y_0 = const()[name = tensor<string, []>("attn_output_7_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 12, 197, 64]> value_7_cast_fp16 = transpose(perm = value_7_perm_0, x = var_276_cast_fp16)[name = tensor<string, []>("transpose_107")];
            tensor<fp16, [1, 12, 197, 64]> attn_output_7_cast_fp16 = matmul(transpose_x = attn_output_7_transpose_x_0, transpose_y = attn_output_7_transpose_y_0, x = softmax_3_cast_fp16, y = value_7_cast_fp16)[name = tensor<string, []>("attn_output_7_cast_fp16")];
            tensor<int32, [4]> var_285_perm_0 = const()[name = tensor<string, []>("op_285_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_289 = const()[name = tensor<string, []>("op_289"), val = tensor<int32, [3]>([1, 197, 768])];
            tensor<fp16, [1, 197, 12, 64]> var_285_cast_fp16 = transpose(perm = var_285_perm_0, x = attn_output_7_cast_fp16)[name = tensor<string, []>("transpose_104")];
            tensor<fp16, [1, 197, 768]> input_53_cast_fp16 = reshape(shape = var_289, x = var_285_cast_fp16)[name = tensor<string, []>("input_53_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_3_attention_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_3_attention_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(47563072)))];
            tensor<fp16, [768]> model_vit_encoder_layer_3_attention_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_3_attention_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(48742784)))];
            tensor<fp16, [1, 197, 768]> linear_21_cast_fp16 = linear(bias = model_vit_encoder_layer_3_attention_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_3_attention_output_dense_weight_to_fp16, x = input_53_cast_fp16)[name = tensor<string, []>("linear_21_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_57_cast_fp16 = add(x = linear_21_cast_fp16, y = input_51_cast_fp16)[name = tensor<string, []>("input_57_cast_fp16")];
            tensor<int32, [1]> input_59_axes_0 = const()[name = tensor<string, []>("input_59_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_3_layernorm_after_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_3_layernorm_after_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(48744384)))];
            tensor<fp16, [768]> model_vit_encoder_layer_3_layernorm_after_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_3_layernorm_after_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(48745984)))];
            tensor<fp16, [1, 197, 768]> input_59_cast_fp16 = layer_norm(axes = input_59_axes_0, beta = model_vit_encoder_layer_3_layernorm_after_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_3_layernorm_after_weight_to_fp16, x = input_57_cast_fp16)[name = tensor<string, []>("input_59_cast_fp16")];
            tensor<fp16, [3072, 768]> model_vit_encoder_layer_3_intermediate_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_3_intermediate_dense_weight_to_fp16"), val = tensor<fp16, [3072, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(48747584)))];
            tensor<fp16, [3072]> model_vit_encoder_layer_3_intermediate_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_3_intermediate_dense_bias_to_fp16"), val = tensor<fp16, [3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(53466240)))];
            tensor<fp16, [1, 197, 3072]> linear_22_cast_fp16 = linear(bias = model_vit_encoder_layer_3_intermediate_dense_bias_to_fp16, weight = model_vit_encoder_layer_3_intermediate_dense_weight_to_fp16, x = input_59_cast_fp16)[name = tensor<string, []>("linear_22_cast_fp16")];
            tensor<string, []> input_63_mode_0 = const()[name = tensor<string, []>("input_63_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 197, 3072]> input_63_cast_fp16 = gelu(mode = input_63_mode_0, x = linear_22_cast_fp16)[name = tensor<string, []>("input_63_cast_fp16")];
            tensor<fp16, [768, 3072]> model_vit_encoder_layer_3_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_3_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(53472448)))];
            tensor<fp16, [768]> model_vit_encoder_layer_3_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_3_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(58191104)))];
            tensor<fp16, [1, 197, 768]> linear_23_cast_fp16 = linear(bias = model_vit_encoder_layer_3_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_3_output_dense_weight_to_fp16, x = input_63_cast_fp16)[name = tensor<string, []>("linear_23_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_67_cast_fp16 = add(x = linear_23_cast_fp16, y = input_57_cast_fp16)[name = tensor<string, []>("input_67_cast_fp16")];
            tensor<int32, [1]> hidden_states_17_axes_0 = const()[name = tensor<string, []>("hidden_states_17_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_4_layernorm_before_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_4_layernorm_before_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(58192704)))];
            tensor<fp16, [768]> model_vit_encoder_layer_4_layernorm_before_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_4_layernorm_before_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(58194304)))];
            tensor<fp16, [1, 197, 768]> hidden_states_17_cast_fp16 = layer_norm(axes = hidden_states_17_axes_0, beta = model_vit_encoder_layer_4_layernorm_before_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_4_layernorm_before_weight_to_fp16, x = input_67_cast_fp16)[name = tensor<string, []>("hidden_states_17_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_4_attention_attention_key_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_4_attention_attention_key_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(58195904)))];
            tensor<fp16, [768]> model_vit_encoder_layer_4_attention_attention_key_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_4_attention_attention_key_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(59375616)))];
            tensor<fp16, [1, 197, 768]> linear_24_cast_fp16 = linear(bias = model_vit_encoder_layer_4_attention_attention_key_bias_to_fp16, weight = model_vit_encoder_layer_4_attention_attention_key_weight_to_fp16, x = hidden_states_17_cast_fp16)[name = tensor<string, []>("linear_24_cast_fp16")];
            tensor<int32, [4]> var_330 = const()[name = tensor<string, []>("op_330"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_331_cast_fp16 = reshape(shape = var_330, x = linear_24_cast_fp16)[name = tensor<string, []>("op_331_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_4_attention_attention_value_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_4_attention_attention_value_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(59377216)))];
            tensor<fp16, [768]> model_vit_encoder_layer_4_attention_attention_value_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_4_attention_attention_value_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(60556928)))];
            tensor<fp16, [1, 197, 768]> linear_25_cast_fp16 = linear(bias = model_vit_encoder_layer_4_attention_attention_value_bias_to_fp16, weight = model_vit_encoder_layer_4_attention_attention_value_weight_to_fp16, x = hidden_states_17_cast_fp16)[name = tensor<string, []>("linear_25_cast_fp16")];
            tensor<int32, [4]> var_336 = const()[name = tensor<string, []>("op_336"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_337_cast_fp16 = reshape(shape = var_336, x = linear_25_cast_fp16)[name = tensor<string, []>("op_337_cast_fp16")];
            tensor<int32, [4]> value_9_perm_0 = const()[name = tensor<string, []>("value_9_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_4_attention_attention_query_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_4_attention_attention_query_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(60558528)))];
            tensor<fp16, [768]> model_vit_encoder_layer_4_attention_attention_query_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_4_attention_attention_query_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(61738240)))];
            tensor<fp16, [1, 197, 768]> linear_26_cast_fp16 = linear(bias = model_vit_encoder_layer_4_attention_attention_query_bias_to_fp16, weight = model_vit_encoder_layer_4_attention_attention_query_weight_to_fp16, x = hidden_states_17_cast_fp16)[name = tensor<string, []>("linear_26_cast_fp16")];
            tensor<int32, [4]> var_342 = const()[name = tensor<string, []>("op_342"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_343_cast_fp16 = reshape(shape = var_342, x = linear_26_cast_fp16)[name = tensor<string, []>("op_343_cast_fp16")];
            tensor<fp16, [1, 197, 12, 64]> mul_4_cast_fp16 = mul(x = var_343_cast_fp16, y = var_17_to_fp16)[name = tensor<string, []>("mul_4_cast_fp16")];
            tensor<bool, []> matmul_4_transpose_y_0 = const()[name = tensor<string, []>("matmul_4_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_4_transpose_x_0 = const()[name = tensor<string, []>("matmul_4_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_56_perm_0 = const()[name = tensor<string, []>("transpose_56_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_57_perm_0 = const()[name = tensor<string, []>("transpose_57_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp16, [1, 12, 197, 64]> transpose_57 = transpose(perm = transpose_57_perm_0, x = var_331_cast_fp16)[name = tensor<string, []>("transpose_101")];
            tensor<fp16, [1, 12, 197, 64]> transpose_56 = transpose(perm = transpose_56_perm_0, x = mul_4_cast_fp16)[name = tensor<string, []>("transpose_102")];
            tensor<fp16, [1, 12, 197, 197]> matmul_4_cast_fp16 = matmul(transpose_x = matmul_4_transpose_x_0, transpose_y = matmul_4_transpose_y_0, x = transpose_56, y = transpose_57)[name = tensor<string, []>("matmul_4_cast_fp16")];
            tensor<int32, []> softmax_4_axis_0 = const()[name = tensor<string, []>("softmax_4_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp16, [1, 12, 197, 197]> softmax_4_cast_fp16 = softmax(axis = softmax_4_axis_0, x = matmul_4_cast_fp16)[name = tensor<string, []>("softmax_4_cast_fp16")];
            tensor<bool, []> attn_output_9_transpose_x_0 = const()[name = tensor<string, []>("attn_output_9_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_9_transpose_y_0 = const()[name = tensor<string, []>("attn_output_9_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 12, 197, 64]> value_9_cast_fp16 = transpose(perm = value_9_perm_0, x = var_337_cast_fp16)[name = tensor<string, []>("transpose_103")];
            tensor<fp16, [1, 12, 197, 64]> attn_output_9_cast_fp16 = matmul(transpose_x = attn_output_9_transpose_x_0, transpose_y = attn_output_9_transpose_y_0, x = softmax_4_cast_fp16, y = value_9_cast_fp16)[name = tensor<string, []>("attn_output_9_cast_fp16")];
            tensor<int32, [4]> var_346_perm_0 = const()[name = tensor<string, []>("op_346_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_350 = const()[name = tensor<string, []>("op_350"), val = tensor<int32, [3]>([1, 197, 768])];
            tensor<fp16, [1, 197, 12, 64]> var_346_cast_fp16 = transpose(perm = var_346_perm_0, x = attn_output_9_cast_fp16)[name = tensor<string, []>("transpose_100")];
            tensor<fp16, [1, 197, 768]> input_69_cast_fp16 = reshape(shape = var_350, x = var_346_cast_fp16)[name = tensor<string, []>("input_69_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_4_attention_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_4_attention_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(61739840)))];
            tensor<fp16, [768]> model_vit_encoder_layer_4_attention_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_4_attention_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(62919552)))];
            tensor<fp16, [1, 197, 768]> linear_27_cast_fp16 = linear(bias = model_vit_encoder_layer_4_attention_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_4_attention_output_dense_weight_to_fp16, x = input_69_cast_fp16)[name = tensor<string, []>("linear_27_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_73_cast_fp16 = add(x = linear_27_cast_fp16, y = input_67_cast_fp16)[name = tensor<string, []>("input_73_cast_fp16")];
            tensor<int32, [1]> input_75_axes_0 = const()[name = tensor<string, []>("input_75_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_4_layernorm_after_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_4_layernorm_after_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(62921152)))];
            tensor<fp16, [768]> model_vit_encoder_layer_4_layernorm_after_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_4_layernorm_after_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(62922752)))];
            tensor<fp16, [1, 197, 768]> input_75_cast_fp16 = layer_norm(axes = input_75_axes_0, beta = model_vit_encoder_layer_4_layernorm_after_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_4_layernorm_after_weight_to_fp16, x = input_73_cast_fp16)[name = tensor<string, []>("input_75_cast_fp16")];
            tensor<fp16, [3072, 768]> model_vit_encoder_layer_4_intermediate_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_4_intermediate_dense_weight_to_fp16"), val = tensor<fp16, [3072, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(62924352)))];
            tensor<fp16, [3072]> model_vit_encoder_layer_4_intermediate_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_4_intermediate_dense_bias_to_fp16"), val = tensor<fp16, [3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(67643008)))];
            tensor<fp16, [1, 197, 3072]> linear_28_cast_fp16 = linear(bias = model_vit_encoder_layer_4_intermediate_dense_bias_to_fp16, weight = model_vit_encoder_layer_4_intermediate_dense_weight_to_fp16, x = input_75_cast_fp16)[name = tensor<string, []>("linear_28_cast_fp16")];
            tensor<string, []> input_79_mode_0 = const()[name = tensor<string, []>("input_79_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 197, 3072]> input_79_cast_fp16 = gelu(mode = input_79_mode_0, x = linear_28_cast_fp16)[name = tensor<string, []>("input_79_cast_fp16")];
            tensor<fp16, [768, 3072]> model_vit_encoder_layer_4_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_4_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(67649216)))];
            tensor<fp16, [768]> model_vit_encoder_layer_4_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_4_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(72367872)))];
            tensor<fp16, [1, 197, 768]> linear_29_cast_fp16 = linear(bias = model_vit_encoder_layer_4_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_4_output_dense_weight_to_fp16, x = input_79_cast_fp16)[name = tensor<string, []>("linear_29_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_83_cast_fp16 = add(x = linear_29_cast_fp16, y = input_73_cast_fp16)[name = tensor<string, []>("input_83_cast_fp16")];
            tensor<int32, [1]> hidden_states_21_axes_0 = const()[name = tensor<string, []>("hidden_states_21_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_5_layernorm_before_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_5_layernorm_before_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(72369472)))];
            tensor<fp16, [768]> model_vit_encoder_layer_5_layernorm_before_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_5_layernorm_before_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(72371072)))];
            tensor<fp16, [1, 197, 768]> hidden_states_21_cast_fp16 = layer_norm(axes = hidden_states_21_axes_0, beta = model_vit_encoder_layer_5_layernorm_before_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_5_layernorm_before_weight_to_fp16, x = input_83_cast_fp16)[name = tensor<string, []>("hidden_states_21_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_5_attention_attention_key_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_5_attention_attention_key_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(72372672)))];
            tensor<fp16, [768]> model_vit_encoder_layer_5_attention_attention_key_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_5_attention_attention_key_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(73552384)))];
            tensor<fp16, [1, 197, 768]> linear_30_cast_fp16 = linear(bias = model_vit_encoder_layer_5_attention_attention_key_bias_to_fp16, weight = model_vit_encoder_layer_5_attention_attention_key_weight_to_fp16, x = hidden_states_21_cast_fp16)[name = tensor<string, []>("linear_30_cast_fp16")];
            tensor<int32, [4]> var_391 = const()[name = tensor<string, []>("op_391"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_392_cast_fp16 = reshape(shape = var_391, x = linear_30_cast_fp16)[name = tensor<string, []>("op_392_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_5_attention_attention_value_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_5_attention_attention_value_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(73553984)))];
            tensor<fp16, [768]> model_vit_encoder_layer_5_attention_attention_value_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_5_attention_attention_value_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(74733696)))];
            tensor<fp16, [1, 197, 768]> linear_31_cast_fp16 = linear(bias = model_vit_encoder_layer_5_attention_attention_value_bias_to_fp16, weight = model_vit_encoder_layer_5_attention_attention_value_weight_to_fp16, x = hidden_states_21_cast_fp16)[name = tensor<string, []>("linear_31_cast_fp16")];
            tensor<int32, [4]> var_397 = const()[name = tensor<string, []>("op_397"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_398_cast_fp16 = reshape(shape = var_397, x = linear_31_cast_fp16)[name = tensor<string, []>("op_398_cast_fp16")];
            tensor<int32, [4]> value_11_perm_0 = const()[name = tensor<string, []>("value_11_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_5_attention_attention_query_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_5_attention_attention_query_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(74735296)))];
            tensor<fp16, [768]> model_vit_encoder_layer_5_attention_attention_query_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_5_attention_attention_query_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(75915008)))];
            tensor<fp16, [1, 197, 768]> linear_32_cast_fp16 = linear(bias = model_vit_encoder_layer_5_attention_attention_query_bias_to_fp16, weight = model_vit_encoder_layer_5_attention_attention_query_weight_to_fp16, x = hidden_states_21_cast_fp16)[name = tensor<string, []>("linear_32_cast_fp16")];
            tensor<int32, [4]> var_403 = const()[name = tensor<string, []>("op_403"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_404_cast_fp16 = reshape(shape = var_403, x = linear_32_cast_fp16)[name = tensor<string, []>("op_404_cast_fp16")];
            tensor<fp16, [1, 197, 12, 64]> mul_5_cast_fp16 = mul(x = var_404_cast_fp16, y = var_17_to_fp16)[name = tensor<string, []>("mul_5_cast_fp16")];
            tensor<bool, []> matmul_5_transpose_y_0 = const()[name = tensor<string, []>("matmul_5_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_5_transpose_x_0 = const()[name = tensor<string, []>("matmul_5_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_58_perm_0 = const()[name = tensor<string, []>("transpose_58_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_59_perm_0 = const()[name = tensor<string, []>("transpose_59_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp16, [1, 12, 197, 64]> transpose_59 = transpose(perm = transpose_59_perm_0, x = var_392_cast_fp16)[name = tensor<string, []>("transpose_97")];
            tensor<fp16, [1, 12, 197, 64]> transpose_58 = transpose(perm = transpose_58_perm_0, x = mul_5_cast_fp16)[name = tensor<string, []>("transpose_98")];
            tensor<fp16, [1, 12, 197, 197]> matmul_5_cast_fp16 = matmul(transpose_x = matmul_5_transpose_x_0, transpose_y = matmul_5_transpose_y_0, x = transpose_58, y = transpose_59)[name = tensor<string, []>("matmul_5_cast_fp16")];
            tensor<int32, []> softmax_5_axis_0 = const()[name = tensor<string, []>("softmax_5_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp16, [1, 12, 197, 197]> softmax_5_cast_fp16 = softmax(axis = softmax_5_axis_0, x = matmul_5_cast_fp16)[name = tensor<string, []>("softmax_5_cast_fp16")];
            tensor<bool, []> attn_output_11_transpose_x_0 = const()[name = tensor<string, []>("attn_output_11_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_11_transpose_y_0 = const()[name = tensor<string, []>("attn_output_11_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 12, 197, 64]> value_11_cast_fp16 = transpose(perm = value_11_perm_0, x = var_398_cast_fp16)[name = tensor<string, []>("transpose_99")];
            tensor<fp16, [1, 12, 197, 64]> attn_output_11_cast_fp16 = matmul(transpose_x = attn_output_11_transpose_x_0, transpose_y = attn_output_11_transpose_y_0, x = softmax_5_cast_fp16, y = value_11_cast_fp16)[name = tensor<string, []>("attn_output_11_cast_fp16")];
            tensor<int32, [4]> var_407_perm_0 = const()[name = tensor<string, []>("op_407_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_411 = const()[name = tensor<string, []>("op_411"), val = tensor<int32, [3]>([1, 197, 768])];
            tensor<fp16, [1, 197, 12, 64]> var_407_cast_fp16 = transpose(perm = var_407_perm_0, x = attn_output_11_cast_fp16)[name = tensor<string, []>("transpose_96")];
            tensor<fp16, [1, 197, 768]> input_85_cast_fp16 = reshape(shape = var_411, x = var_407_cast_fp16)[name = tensor<string, []>("input_85_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_5_attention_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_5_attention_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(75916608)))];
            tensor<fp16, [768]> model_vit_encoder_layer_5_attention_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_5_attention_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(77096320)))];
            tensor<fp16, [1, 197, 768]> linear_33_cast_fp16 = linear(bias = model_vit_encoder_layer_5_attention_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_5_attention_output_dense_weight_to_fp16, x = input_85_cast_fp16)[name = tensor<string, []>("linear_33_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_89_cast_fp16 = add(x = linear_33_cast_fp16, y = input_83_cast_fp16)[name = tensor<string, []>("input_89_cast_fp16")];
            tensor<int32, [1]> input_91_axes_0 = const()[name = tensor<string, []>("input_91_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_5_layernorm_after_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_5_layernorm_after_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(77097920)))];
            tensor<fp16, [768]> model_vit_encoder_layer_5_layernorm_after_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_5_layernorm_after_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(77099520)))];
            tensor<fp16, [1, 197, 768]> input_91_cast_fp16 = layer_norm(axes = input_91_axes_0, beta = model_vit_encoder_layer_5_layernorm_after_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_5_layernorm_after_weight_to_fp16, x = input_89_cast_fp16)[name = tensor<string, []>("input_91_cast_fp16")];
            tensor<fp16, [3072, 768]> model_vit_encoder_layer_5_intermediate_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_5_intermediate_dense_weight_to_fp16"), val = tensor<fp16, [3072, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(77101120)))];
            tensor<fp16, [3072]> model_vit_encoder_layer_5_intermediate_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_5_intermediate_dense_bias_to_fp16"), val = tensor<fp16, [3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(81819776)))];
            tensor<fp16, [1, 197, 3072]> linear_34_cast_fp16 = linear(bias = model_vit_encoder_layer_5_intermediate_dense_bias_to_fp16, weight = model_vit_encoder_layer_5_intermediate_dense_weight_to_fp16, x = input_91_cast_fp16)[name = tensor<string, []>("linear_34_cast_fp16")];
            tensor<string, []> input_95_mode_0 = const()[name = tensor<string, []>("input_95_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 197, 3072]> input_95_cast_fp16 = gelu(mode = input_95_mode_0, x = linear_34_cast_fp16)[name = tensor<string, []>("input_95_cast_fp16")];
            tensor<fp16, [768, 3072]> model_vit_encoder_layer_5_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_5_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(81825984)))];
            tensor<fp16, [768]> model_vit_encoder_layer_5_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_5_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(86544640)))];
            tensor<fp16, [1, 197, 768]> linear_35_cast_fp16 = linear(bias = model_vit_encoder_layer_5_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_5_output_dense_weight_to_fp16, x = input_95_cast_fp16)[name = tensor<string, []>("linear_35_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_99_cast_fp16 = add(x = linear_35_cast_fp16, y = input_89_cast_fp16)[name = tensor<string, []>("input_99_cast_fp16")];
            tensor<int32, [1]> hidden_states_25_axes_0 = const()[name = tensor<string, []>("hidden_states_25_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_6_layernorm_before_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_6_layernorm_before_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(86546240)))];
            tensor<fp16, [768]> model_vit_encoder_layer_6_layernorm_before_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_6_layernorm_before_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(86547840)))];
            tensor<fp16, [1, 197, 768]> hidden_states_25_cast_fp16 = layer_norm(axes = hidden_states_25_axes_0, beta = model_vit_encoder_layer_6_layernorm_before_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_6_layernorm_before_weight_to_fp16, x = input_99_cast_fp16)[name = tensor<string, []>("hidden_states_25_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_6_attention_attention_key_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_6_attention_attention_key_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(86549440)))];
            tensor<fp16, [768]> model_vit_encoder_layer_6_attention_attention_key_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_6_attention_attention_key_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(87729152)))];
            tensor<fp16, [1, 197, 768]> linear_36_cast_fp16 = linear(bias = model_vit_encoder_layer_6_attention_attention_key_bias_to_fp16, weight = model_vit_encoder_layer_6_attention_attention_key_weight_to_fp16, x = hidden_states_25_cast_fp16)[name = tensor<string, []>("linear_36_cast_fp16")];
            tensor<int32, [4]> var_452 = const()[name = tensor<string, []>("op_452"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_453_cast_fp16 = reshape(shape = var_452, x = linear_36_cast_fp16)[name = tensor<string, []>("op_453_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_6_attention_attention_value_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_6_attention_attention_value_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(87730752)))];
            tensor<fp16, [768]> model_vit_encoder_layer_6_attention_attention_value_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_6_attention_attention_value_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(88910464)))];
            tensor<fp16, [1, 197, 768]> linear_37_cast_fp16 = linear(bias = model_vit_encoder_layer_6_attention_attention_value_bias_to_fp16, weight = model_vit_encoder_layer_6_attention_attention_value_weight_to_fp16, x = hidden_states_25_cast_fp16)[name = tensor<string, []>("linear_37_cast_fp16")];
            tensor<int32, [4]> var_458 = const()[name = tensor<string, []>("op_458"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_459_cast_fp16 = reshape(shape = var_458, x = linear_37_cast_fp16)[name = tensor<string, []>("op_459_cast_fp16")];
            tensor<int32, [4]> value_13_perm_0 = const()[name = tensor<string, []>("value_13_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_6_attention_attention_query_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_6_attention_attention_query_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(88912064)))];
            tensor<fp16, [768]> model_vit_encoder_layer_6_attention_attention_query_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_6_attention_attention_query_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(90091776)))];
            tensor<fp16, [1, 197, 768]> linear_38_cast_fp16 = linear(bias = model_vit_encoder_layer_6_attention_attention_query_bias_to_fp16, weight = model_vit_encoder_layer_6_attention_attention_query_weight_to_fp16, x = hidden_states_25_cast_fp16)[name = tensor<string, []>("linear_38_cast_fp16")];
            tensor<int32, [4]> var_464 = const()[name = tensor<string, []>("op_464"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_465_cast_fp16 = reshape(shape = var_464, x = linear_38_cast_fp16)[name = tensor<string, []>("op_465_cast_fp16")];
            tensor<fp16, [1, 197, 12, 64]> mul_6_cast_fp16 = mul(x = var_465_cast_fp16, y = var_17_to_fp16)[name = tensor<string, []>("mul_6_cast_fp16")];
            tensor<bool, []> matmul_6_transpose_y_0 = const()[name = tensor<string, []>("matmul_6_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_6_transpose_x_0 = const()[name = tensor<string, []>("matmul_6_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_60_perm_0 = const()[name = tensor<string, []>("transpose_60_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_61_perm_0 = const()[name = tensor<string, []>("transpose_61_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp16, [1, 12, 197, 64]> transpose_61 = transpose(perm = transpose_61_perm_0, x = var_453_cast_fp16)[name = tensor<string, []>("transpose_93")];
            tensor<fp16, [1, 12, 197, 64]> transpose_60 = transpose(perm = transpose_60_perm_0, x = mul_6_cast_fp16)[name = tensor<string, []>("transpose_94")];
            tensor<fp16, [1, 12, 197, 197]> matmul_6_cast_fp16 = matmul(transpose_x = matmul_6_transpose_x_0, transpose_y = matmul_6_transpose_y_0, x = transpose_60, y = transpose_61)[name = tensor<string, []>("matmul_6_cast_fp16")];
            tensor<int32, []> softmax_6_axis_0 = const()[name = tensor<string, []>("softmax_6_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp16, [1, 12, 197, 197]> softmax_6_cast_fp16 = softmax(axis = softmax_6_axis_0, x = matmul_6_cast_fp16)[name = tensor<string, []>("softmax_6_cast_fp16")];
            tensor<bool, []> attn_output_13_transpose_x_0 = const()[name = tensor<string, []>("attn_output_13_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_13_transpose_y_0 = const()[name = tensor<string, []>("attn_output_13_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 12, 197, 64]> value_13_cast_fp16 = transpose(perm = value_13_perm_0, x = var_459_cast_fp16)[name = tensor<string, []>("transpose_95")];
            tensor<fp16, [1, 12, 197, 64]> attn_output_13_cast_fp16 = matmul(transpose_x = attn_output_13_transpose_x_0, transpose_y = attn_output_13_transpose_y_0, x = softmax_6_cast_fp16, y = value_13_cast_fp16)[name = tensor<string, []>("attn_output_13_cast_fp16")];
            tensor<int32, [4]> var_468_perm_0 = const()[name = tensor<string, []>("op_468_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_472 = const()[name = tensor<string, []>("op_472"), val = tensor<int32, [3]>([1, 197, 768])];
            tensor<fp16, [1, 197, 12, 64]> var_468_cast_fp16 = transpose(perm = var_468_perm_0, x = attn_output_13_cast_fp16)[name = tensor<string, []>("transpose_92")];
            tensor<fp16, [1, 197, 768]> input_101_cast_fp16 = reshape(shape = var_472, x = var_468_cast_fp16)[name = tensor<string, []>("input_101_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_6_attention_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_6_attention_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(90093376)))];
            tensor<fp16, [768]> model_vit_encoder_layer_6_attention_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_6_attention_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(91273088)))];
            tensor<fp16, [1, 197, 768]> linear_39_cast_fp16 = linear(bias = model_vit_encoder_layer_6_attention_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_6_attention_output_dense_weight_to_fp16, x = input_101_cast_fp16)[name = tensor<string, []>("linear_39_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_105_cast_fp16 = add(x = linear_39_cast_fp16, y = input_99_cast_fp16)[name = tensor<string, []>("input_105_cast_fp16")];
            tensor<int32, [1]> input_107_axes_0 = const()[name = tensor<string, []>("input_107_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_6_layernorm_after_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_6_layernorm_after_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(91274688)))];
            tensor<fp16, [768]> model_vit_encoder_layer_6_layernorm_after_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_6_layernorm_after_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(91276288)))];
            tensor<fp16, [1, 197, 768]> input_107_cast_fp16 = layer_norm(axes = input_107_axes_0, beta = model_vit_encoder_layer_6_layernorm_after_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_6_layernorm_after_weight_to_fp16, x = input_105_cast_fp16)[name = tensor<string, []>("input_107_cast_fp16")];
            tensor<fp16, [3072, 768]> model_vit_encoder_layer_6_intermediate_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_6_intermediate_dense_weight_to_fp16"), val = tensor<fp16, [3072, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(91277888)))];
            tensor<fp16, [3072]> model_vit_encoder_layer_6_intermediate_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_6_intermediate_dense_bias_to_fp16"), val = tensor<fp16, [3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(95996544)))];
            tensor<fp16, [1, 197, 3072]> linear_40_cast_fp16 = linear(bias = model_vit_encoder_layer_6_intermediate_dense_bias_to_fp16, weight = model_vit_encoder_layer_6_intermediate_dense_weight_to_fp16, x = input_107_cast_fp16)[name = tensor<string, []>("linear_40_cast_fp16")];
            tensor<string, []> input_111_mode_0 = const()[name = tensor<string, []>("input_111_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 197, 3072]> input_111_cast_fp16 = gelu(mode = input_111_mode_0, x = linear_40_cast_fp16)[name = tensor<string, []>("input_111_cast_fp16")];
            tensor<fp16, [768, 3072]> model_vit_encoder_layer_6_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_6_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(96002752)))];
            tensor<fp16, [768]> model_vit_encoder_layer_6_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_6_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(100721408)))];
            tensor<fp16, [1, 197, 768]> linear_41_cast_fp16 = linear(bias = model_vit_encoder_layer_6_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_6_output_dense_weight_to_fp16, x = input_111_cast_fp16)[name = tensor<string, []>("linear_41_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_115_cast_fp16 = add(x = linear_41_cast_fp16, y = input_105_cast_fp16)[name = tensor<string, []>("input_115_cast_fp16")];
            tensor<int32, [1]> hidden_states_29_axes_0 = const()[name = tensor<string, []>("hidden_states_29_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_7_layernorm_before_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_7_layernorm_before_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(100723008)))];
            tensor<fp16, [768]> model_vit_encoder_layer_7_layernorm_before_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_7_layernorm_before_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(100724608)))];
            tensor<fp16, [1, 197, 768]> hidden_states_29_cast_fp16 = layer_norm(axes = hidden_states_29_axes_0, beta = model_vit_encoder_layer_7_layernorm_before_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_7_layernorm_before_weight_to_fp16, x = input_115_cast_fp16)[name = tensor<string, []>("hidden_states_29_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_7_attention_attention_key_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_7_attention_attention_key_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(100726208)))];
            tensor<fp16, [768]> model_vit_encoder_layer_7_attention_attention_key_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_7_attention_attention_key_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(101905920)))];
            tensor<fp16, [1, 197, 768]> linear_42_cast_fp16 = linear(bias = model_vit_encoder_layer_7_attention_attention_key_bias_to_fp16, weight = model_vit_encoder_layer_7_attention_attention_key_weight_to_fp16, x = hidden_states_29_cast_fp16)[name = tensor<string, []>("linear_42_cast_fp16")];
            tensor<int32, [4]> var_513 = const()[name = tensor<string, []>("op_513"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_514_cast_fp16 = reshape(shape = var_513, x = linear_42_cast_fp16)[name = tensor<string, []>("op_514_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_7_attention_attention_value_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_7_attention_attention_value_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(101907520)))];
            tensor<fp16, [768]> model_vit_encoder_layer_7_attention_attention_value_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_7_attention_attention_value_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(103087232)))];
            tensor<fp16, [1, 197, 768]> linear_43_cast_fp16 = linear(bias = model_vit_encoder_layer_7_attention_attention_value_bias_to_fp16, weight = model_vit_encoder_layer_7_attention_attention_value_weight_to_fp16, x = hidden_states_29_cast_fp16)[name = tensor<string, []>("linear_43_cast_fp16")];
            tensor<int32, [4]> var_519 = const()[name = tensor<string, []>("op_519"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_520_cast_fp16 = reshape(shape = var_519, x = linear_43_cast_fp16)[name = tensor<string, []>("op_520_cast_fp16")];
            tensor<int32, [4]> value_15_perm_0 = const()[name = tensor<string, []>("value_15_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_7_attention_attention_query_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_7_attention_attention_query_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(103088832)))];
            tensor<fp16, [768]> model_vit_encoder_layer_7_attention_attention_query_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_7_attention_attention_query_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(104268544)))];
            tensor<fp16, [1, 197, 768]> linear_44_cast_fp16 = linear(bias = model_vit_encoder_layer_7_attention_attention_query_bias_to_fp16, weight = model_vit_encoder_layer_7_attention_attention_query_weight_to_fp16, x = hidden_states_29_cast_fp16)[name = tensor<string, []>("linear_44_cast_fp16")];
            tensor<int32, [4]> var_525 = const()[name = tensor<string, []>("op_525"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_526_cast_fp16 = reshape(shape = var_525, x = linear_44_cast_fp16)[name = tensor<string, []>("op_526_cast_fp16")];
            tensor<fp16, [1, 197, 12, 64]> mul_7_cast_fp16 = mul(x = var_526_cast_fp16, y = var_17_to_fp16)[name = tensor<string, []>("mul_7_cast_fp16")];
            tensor<bool, []> matmul_7_transpose_y_0 = const()[name = tensor<string, []>("matmul_7_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_7_transpose_x_0 = const()[name = tensor<string, []>("matmul_7_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_62_perm_0 = const()[name = tensor<string, []>("transpose_62_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_63_perm_0 = const()[name = tensor<string, []>("transpose_63_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp16, [1, 12, 197, 64]> transpose_63 = transpose(perm = transpose_63_perm_0, x = var_514_cast_fp16)[name = tensor<string, []>("transpose_89")];
            tensor<fp16, [1, 12, 197, 64]> transpose_62 = transpose(perm = transpose_62_perm_0, x = mul_7_cast_fp16)[name = tensor<string, []>("transpose_90")];
            tensor<fp16, [1, 12, 197, 197]> matmul_7_cast_fp16 = matmul(transpose_x = matmul_7_transpose_x_0, transpose_y = matmul_7_transpose_y_0, x = transpose_62, y = transpose_63)[name = tensor<string, []>("matmul_7_cast_fp16")];
            tensor<int32, []> softmax_7_axis_0 = const()[name = tensor<string, []>("softmax_7_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp16, [1, 12, 197, 197]> softmax_7_cast_fp16 = softmax(axis = softmax_7_axis_0, x = matmul_7_cast_fp16)[name = tensor<string, []>("softmax_7_cast_fp16")];
            tensor<bool, []> attn_output_15_transpose_x_0 = const()[name = tensor<string, []>("attn_output_15_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_15_transpose_y_0 = const()[name = tensor<string, []>("attn_output_15_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 12, 197, 64]> value_15_cast_fp16 = transpose(perm = value_15_perm_0, x = var_520_cast_fp16)[name = tensor<string, []>("transpose_91")];
            tensor<fp16, [1, 12, 197, 64]> attn_output_15_cast_fp16 = matmul(transpose_x = attn_output_15_transpose_x_0, transpose_y = attn_output_15_transpose_y_0, x = softmax_7_cast_fp16, y = value_15_cast_fp16)[name = tensor<string, []>("attn_output_15_cast_fp16")];
            tensor<int32, [4]> var_529_perm_0 = const()[name = tensor<string, []>("op_529_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_533 = const()[name = tensor<string, []>("op_533"), val = tensor<int32, [3]>([1, 197, 768])];
            tensor<fp16, [1, 197, 12, 64]> var_529_cast_fp16 = transpose(perm = var_529_perm_0, x = attn_output_15_cast_fp16)[name = tensor<string, []>("transpose_88")];
            tensor<fp16, [1, 197, 768]> input_117_cast_fp16 = reshape(shape = var_533, x = var_529_cast_fp16)[name = tensor<string, []>("input_117_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_7_attention_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_7_attention_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(104270144)))];
            tensor<fp16, [768]> model_vit_encoder_layer_7_attention_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_7_attention_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(105449856)))];
            tensor<fp16, [1, 197, 768]> linear_45_cast_fp16 = linear(bias = model_vit_encoder_layer_7_attention_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_7_attention_output_dense_weight_to_fp16, x = input_117_cast_fp16)[name = tensor<string, []>("linear_45_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_121_cast_fp16 = add(x = linear_45_cast_fp16, y = input_115_cast_fp16)[name = tensor<string, []>("input_121_cast_fp16")];
            tensor<int32, [1]> input_123_axes_0 = const()[name = tensor<string, []>("input_123_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_7_layernorm_after_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_7_layernorm_after_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(105451456)))];
            tensor<fp16, [768]> model_vit_encoder_layer_7_layernorm_after_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_7_layernorm_after_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(105453056)))];
            tensor<fp16, [1, 197, 768]> input_123_cast_fp16 = layer_norm(axes = input_123_axes_0, beta = model_vit_encoder_layer_7_layernorm_after_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_7_layernorm_after_weight_to_fp16, x = input_121_cast_fp16)[name = tensor<string, []>("input_123_cast_fp16")];
            tensor<fp16, [3072, 768]> model_vit_encoder_layer_7_intermediate_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_7_intermediate_dense_weight_to_fp16"), val = tensor<fp16, [3072, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(105454656)))];
            tensor<fp16, [3072]> model_vit_encoder_layer_7_intermediate_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_7_intermediate_dense_bias_to_fp16"), val = tensor<fp16, [3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(110173312)))];
            tensor<fp16, [1, 197, 3072]> linear_46_cast_fp16 = linear(bias = model_vit_encoder_layer_7_intermediate_dense_bias_to_fp16, weight = model_vit_encoder_layer_7_intermediate_dense_weight_to_fp16, x = input_123_cast_fp16)[name = tensor<string, []>("linear_46_cast_fp16")];
            tensor<string, []> input_127_mode_0 = const()[name = tensor<string, []>("input_127_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 197, 3072]> input_127_cast_fp16 = gelu(mode = input_127_mode_0, x = linear_46_cast_fp16)[name = tensor<string, []>("input_127_cast_fp16")];
            tensor<fp16, [768, 3072]> model_vit_encoder_layer_7_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_7_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(110179520)))];
            tensor<fp16, [768]> model_vit_encoder_layer_7_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_7_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(114898176)))];
            tensor<fp16, [1, 197, 768]> linear_47_cast_fp16 = linear(bias = model_vit_encoder_layer_7_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_7_output_dense_weight_to_fp16, x = input_127_cast_fp16)[name = tensor<string, []>("linear_47_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_131_cast_fp16 = add(x = linear_47_cast_fp16, y = input_121_cast_fp16)[name = tensor<string, []>("input_131_cast_fp16")];
            tensor<int32, [1]> hidden_states_33_axes_0 = const()[name = tensor<string, []>("hidden_states_33_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_8_layernorm_before_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_8_layernorm_before_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(114899776)))];
            tensor<fp16, [768]> model_vit_encoder_layer_8_layernorm_before_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_8_layernorm_before_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(114901376)))];
            tensor<fp16, [1, 197, 768]> hidden_states_33_cast_fp16 = layer_norm(axes = hidden_states_33_axes_0, beta = model_vit_encoder_layer_8_layernorm_before_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_8_layernorm_before_weight_to_fp16, x = input_131_cast_fp16)[name = tensor<string, []>("hidden_states_33_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_8_attention_attention_key_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_8_attention_attention_key_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(114902976)))];
            tensor<fp16, [768]> model_vit_encoder_layer_8_attention_attention_key_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_8_attention_attention_key_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(116082688)))];
            tensor<fp16, [1, 197, 768]> linear_48_cast_fp16 = linear(bias = model_vit_encoder_layer_8_attention_attention_key_bias_to_fp16, weight = model_vit_encoder_layer_8_attention_attention_key_weight_to_fp16, x = hidden_states_33_cast_fp16)[name = tensor<string, []>("linear_48_cast_fp16")];
            tensor<int32, [4]> var_574 = const()[name = tensor<string, []>("op_574"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_575_cast_fp16 = reshape(shape = var_574, x = linear_48_cast_fp16)[name = tensor<string, []>("op_575_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_8_attention_attention_value_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_8_attention_attention_value_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(116084288)))];
            tensor<fp16, [768]> model_vit_encoder_layer_8_attention_attention_value_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_8_attention_attention_value_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(117264000)))];
            tensor<fp16, [1, 197, 768]> linear_49_cast_fp16 = linear(bias = model_vit_encoder_layer_8_attention_attention_value_bias_to_fp16, weight = model_vit_encoder_layer_8_attention_attention_value_weight_to_fp16, x = hidden_states_33_cast_fp16)[name = tensor<string, []>("linear_49_cast_fp16")];
            tensor<int32, [4]> var_580 = const()[name = tensor<string, []>("op_580"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_581_cast_fp16 = reshape(shape = var_580, x = linear_49_cast_fp16)[name = tensor<string, []>("op_581_cast_fp16")];
            tensor<int32, [4]> value_17_perm_0 = const()[name = tensor<string, []>("value_17_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_8_attention_attention_query_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_8_attention_attention_query_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(117265600)))];
            tensor<fp16, [768]> model_vit_encoder_layer_8_attention_attention_query_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_8_attention_attention_query_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(118445312)))];
            tensor<fp16, [1, 197, 768]> linear_50_cast_fp16 = linear(bias = model_vit_encoder_layer_8_attention_attention_query_bias_to_fp16, weight = model_vit_encoder_layer_8_attention_attention_query_weight_to_fp16, x = hidden_states_33_cast_fp16)[name = tensor<string, []>("linear_50_cast_fp16")];
            tensor<int32, [4]> var_586 = const()[name = tensor<string, []>("op_586"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_587_cast_fp16 = reshape(shape = var_586, x = linear_50_cast_fp16)[name = tensor<string, []>("op_587_cast_fp16")];
            tensor<fp16, [1, 197, 12, 64]> mul_8_cast_fp16 = mul(x = var_587_cast_fp16, y = var_17_to_fp16)[name = tensor<string, []>("mul_8_cast_fp16")];
            tensor<bool, []> matmul_8_transpose_y_0 = const()[name = tensor<string, []>("matmul_8_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_8_transpose_x_0 = const()[name = tensor<string, []>("matmul_8_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_64_perm_0 = const()[name = tensor<string, []>("transpose_64_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_65_perm_0 = const()[name = tensor<string, []>("transpose_65_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp16, [1, 12, 197, 64]> transpose_65 = transpose(perm = transpose_65_perm_0, x = var_575_cast_fp16)[name = tensor<string, []>("transpose_85")];
            tensor<fp16, [1, 12, 197, 64]> transpose_64 = transpose(perm = transpose_64_perm_0, x = mul_8_cast_fp16)[name = tensor<string, []>("transpose_86")];
            tensor<fp16, [1, 12, 197, 197]> matmul_8_cast_fp16 = matmul(transpose_x = matmul_8_transpose_x_0, transpose_y = matmul_8_transpose_y_0, x = transpose_64, y = transpose_65)[name = tensor<string, []>("matmul_8_cast_fp16")];
            tensor<int32, []> softmax_8_axis_0 = const()[name = tensor<string, []>("softmax_8_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp16, [1, 12, 197, 197]> softmax_8_cast_fp16 = softmax(axis = softmax_8_axis_0, x = matmul_8_cast_fp16)[name = tensor<string, []>("softmax_8_cast_fp16")];
            tensor<bool, []> attn_output_17_transpose_x_0 = const()[name = tensor<string, []>("attn_output_17_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_17_transpose_y_0 = const()[name = tensor<string, []>("attn_output_17_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 12, 197, 64]> value_17_cast_fp16 = transpose(perm = value_17_perm_0, x = var_581_cast_fp16)[name = tensor<string, []>("transpose_87")];
            tensor<fp16, [1, 12, 197, 64]> attn_output_17_cast_fp16 = matmul(transpose_x = attn_output_17_transpose_x_0, transpose_y = attn_output_17_transpose_y_0, x = softmax_8_cast_fp16, y = value_17_cast_fp16)[name = tensor<string, []>("attn_output_17_cast_fp16")];
            tensor<int32, [4]> var_590_perm_0 = const()[name = tensor<string, []>("op_590_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_594 = const()[name = tensor<string, []>("op_594"), val = tensor<int32, [3]>([1, 197, 768])];
            tensor<fp16, [1, 197, 12, 64]> var_590_cast_fp16 = transpose(perm = var_590_perm_0, x = attn_output_17_cast_fp16)[name = tensor<string, []>("transpose_84")];
            tensor<fp16, [1, 197, 768]> input_133_cast_fp16 = reshape(shape = var_594, x = var_590_cast_fp16)[name = tensor<string, []>("input_133_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_8_attention_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_8_attention_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(118446912)))];
            tensor<fp16, [768]> model_vit_encoder_layer_8_attention_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_8_attention_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(119626624)))];
            tensor<fp16, [1, 197, 768]> linear_51_cast_fp16 = linear(bias = model_vit_encoder_layer_8_attention_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_8_attention_output_dense_weight_to_fp16, x = input_133_cast_fp16)[name = tensor<string, []>("linear_51_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_137_cast_fp16 = add(x = linear_51_cast_fp16, y = input_131_cast_fp16)[name = tensor<string, []>("input_137_cast_fp16")];
            tensor<int32, [1]> input_139_axes_0 = const()[name = tensor<string, []>("input_139_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_8_layernorm_after_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_8_layernorm_after_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(119628224)))];
            tensor<fp16, [768]> model_vit_encoder_layer_8_layernorm_after_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_8_layernorm_after_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(119629824)))];
            tensor<fp16, [1, 197, 768]> input_139_cast_fp16 = layer_norm(axes = input_139_axes_0, beta = model_vit_encoder_layer_8_layernorm_after_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_8_layernorm_after_weight_to_fp16, x = input_137_cast_fp16)[name = tensor<string, []>("input_139_cast_fp16")];
            tensor<fp16, [3072, 768]> model_vit_encoder_layer_8_intermediate_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_8_intermediate_dense_weight_to_fp16"), val = tensor<fp16, [3072, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(119631424)))];
            tensor<fp16, [3072]> model_vit_encoder_layer_8_intermediate_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_8_intermediate_dense_bias_to_fp16"), val = tensor<fp16, [3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(124350080)))];
            tensor<fp16, [1, 197, 3072]> linear_52_cast_fp16 = linear(bias = model_vit_encoder_layer_8_intermediate_dense_bias_to_fp16, weight = model_vit_encoder_layer_8_intermediate_dense_weight_to_fp16, x = input_139_cast_fp16)[name = tensor<string, []>("linear_52_cast_fp16")];
            tensor<string, []> input_143_mode_0 = const()[name = tensor<string, []>("input_143_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 197, 3072]> input_143_cast_fp16 = gelu(mode = input_143_mode_0, x = linear_52_cast_fp16)[name = tensor<string, []>("input_143_cast_fp16")];
            tensor<fp16, [768, 3072]> model_vit_encoder_layer_8_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_8_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(124356288)))];
            tensor<fp16, [768]> model_vit_encoder_layer_8_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_8_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(129074944)))];
            tensor<fp16, [1, 197, 768]> linear_53_cast_fp16 = linear(bias = model_vit_encoder_layer_8_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_8_output_dense_weight_to_fp16, x = input_143_cast_fp16)[name = tensor<string, []>("linear_53_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_147_cast_fp16 = add(x = linear_53_cast_fp16, y = input_137_cast_fp16)[name = tensor<string, []>("input_147_cast_fp16")];
            tensor<int32, [1]> hidden_states_37_axes_0 = const()[name = tensor<string, []>("hidden_states_37_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_9_layernorm_before_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_9_layernorm_before_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(129076544)))];
            tensor<fp16, [768]> model_vit_encoder_layer_9_layernorm_before_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_9_layernorm_before_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(129078144)))];
            tensor<fp16, [1, 197, 768]> hidden_states_37_cast_fp16 = layer_norm(axes = hidden_states_37_axes_0, beta = model_vit_encoder_layer_9_layernorm_before_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_9_layernorm_before_weight_to_fp16, x = input_147_cast_fp16)[name = tensor<string, []>("hidden_states_37_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_9_attention_attention_key_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_9_attention_attention_key_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(129079744)))];
            tensor<fp16, [768]> model_vit_encoder_layer_9_attention_attention_key_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_9_attention_attention_key_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(130259456)))];
            tensor<fp16, [1, 197, 768]> linear_54_cast_fp16 = linear(bias = model_vit_encoder_layer_9_attention_attention_key_bias_to_fp16, weight = model_vit_encoder_layer_9_attention_attention_key_weight_to_fp16, x = hidden_states_37_cast_fp16)[name = tensor<string, []>("linear_54_cast_fp16")];
            tensor<int32, [4]> var_635 = const()[name = tensor<string, []>("op_635"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_636_cast_fp16 = reshape(shape = var_635, x = linear_54_cast_fp16)[name = tensor<string, []>("op_636_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_9_attention_attention_value_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_9_attention_attention_value_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(130261056)))];
            tensor<fp16, [768]> model_vit_encoder_layer_9_attention_attention_value_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_9_attention_attention_value_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(131440768)))];
            tensor<fp16, [1, 197, 768]> linear_55_cast_fp16 = linear(bias = model_vit_encoder_layer_9_attention_attention_value_bias_to_fp16, weight = model_vit_encoder_layer_9_attention_attention_value_weight_to_fp16, x = hidden_states_37_cast_fp16)[name = tensor<string, []>("linear_55_cast_fp16")];
            tensor<int32, [4]> var_641 = const()[name = tensor<string, []>("op_641"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_642_cast_fp16 = reshape(shape = var_641, x = linear_55_cast_fp16)[name = tensor<string, []>("op_642_cast_fp16")];
            tensor<int32, [4]> value_19_perm_0 = const()[name = tensor<string, []>("value_19_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_9_attention_attention_query_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_9_attention_attention_query_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(131442368)))];
            tensor<fp16, [768]> model_vit_encoder_layer_9_attention_attention_query_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_9_attention_attention_query_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(132622080)))];
            tensor<fp16, [1, 197, 768]> linear_56_cast_fp16 = linear(bias = model_vit_encoder_layer_9_attention_attention_query_bias_to_fp16, weight = model_vit_encoder_layer_9_attention_attention_query_weight_to_fp16, x = hidden_states_37_cast_fp16)[name = tensor<string, []>("linear_56_cast_fp16")];
            tensor<int32, [4]> var_647 = const()[name = tensor<string, []>("op_647"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_648_cast_fp16 = reshape(shape = var_647, x = linear_56_cast_fp16)[name = tensor<string, []>("op_648_cast_fp16")];
            tensor<fp16, [1, 197, 12, 64]> mul_9_cast_fp16 = mul(x = var_648_cast_fp16, y = var_17_to_fp16)[name = tensor<string, []>("mul_9_cast_fp16")];
            tensor<bool, []> matmul_9_transpose_y_0 = const()[name = tensor<string, []>("matmul_9_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_9_transpose_x_0 = const()[name = tensor<string, []>("matmul_9_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_66_perm_0 = const()[name = tensor<string, []>("transpose_66_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_67_perm_0 = const()[name = tensor<string, []>("transpose_67_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp16, [1, 12, 197, 64]> transpose_67 = transpose(perm = transpose_67_perm_0, x = var_636_cast_fp16)[name = tensor<string, []>("transpose_81")];
            tensor<fp16, [1, 12, 197, 64]> transpose_66 = transpose(perm = transpose_66_perm_0, x = mul_9_cast_fp16)[name = tensor<string, []>("transpose_82")];
            tensor<fp16, [1, 12, 197, 197]> matmul_9_cast_fp16 = matmul(transpose_x = matmul_9_transpose_x_0, transpose_y = matmul_9_transpose_y_0, x = transpose_66, y = transpose_67)[name = tensor<string, []>("matmul_9_cast_fp16")];
            tensor<int32, []> softmax_9_axis_0 = const()[name = tensor<string, []>("softmax_9_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp16, [1, 12, 197, 197]> softmax_9_cast_fp16 = softmax(axis = softmax_9_axis_0, x = matmul_9_cast_fp16)[name = tensor<string, []>("softmax_9_cast_fp16")];
            tensor<bool, []> attn_output_19_transpose_x_0 = const()[name = tensor<string, []>("attn_output_19_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_19_transpose_y_0 = const()[name = tensor<string, []>("attn_output_19_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 12, 197, 64]> value_19_cast_fp16 = transpose(perm = value_19_perm_0, x = var_642_cast_fp16)[name = tensor<string, []>("transpose_83")];
            tensor<fp16, [1, 12, 197, 64]> attn_output_19_cast_fp16 = matmul(transpose_x = attn_output_19_transpose_x_0, transpose_y = attn_output_19_transpose_y_0, x = softmax_9_cast_fp16, y = value_19_cast_fp16)[name = tensor<string, []>("attn_output_19_cast_fp16")];
            tensor<int32, [4]> var_651_perm_0 = const()[name = tensor<string, []>("op_651_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_655 = const()[name = tensor<string, []>("op_655"), val = tensor<int32, [3]>([1, 197, 768])];
            tensor<fp16, [1, 197, 12, 64]> var_651_cast_fp16 = transpose(perm = var_651_perm_0, x = attn_output_19_cast_fp16)[name = tensor<string, []>("transpose_80")];
            tensor<fp16, [1, 197, 768]> input_149_cast_fp16 = reshape(shape = var_655, x = var_651_cast_fp16)[name = tensor<string, []>("input_149_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_9_attention_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_9_attention_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(132623680)))];
            tensor<fp16, [768]> model_vit_encoder_layer_9_attention_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_9_attention_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(133803392)))];
            tensor<fp16, [1, 197, 768]> linear_57_cast_fp16 = linear(bias = model_vit_encoder_layer_9_attention_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_9_attention_output_dense_weight_to_fp16, x = input_149_cast_fp16)[name = tensor<string, []>("linear_57_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_153_cast_fp16 = add(x = linear_57_cast_fp16, y = input_147_cast_fp16)[name = tensor<string, []>("input_153_cast_fp16")];
            tensor<int32, [1]> input_155_axes_0 = const()[name = tensor<string, []>("input_155_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_9_layernorm_after_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_9_layernorm_after_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(133804992)))];
            tensor<fp16, [768]> model_vit_encoder_layer_9_layernorm_after_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_9_layernorm_after_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(133806592)))];
            tensor<fp16, [1, 197, 768]> input_155_cast_fp16 = layer_norm(axes = input_155_axes_0, beta = model_vit_encoder_layer_9_layernorm_after_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_9_layernorm_after_weight_to_fp16, x = input_153_cast_fp16)[name = tensor<string, []>("input_155_cast_fp16")];
            tensor<fp16, [3072, 768]> model_vit_encoder_layer_9_intermediate_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_9_intermediate_dense_weight_to_fp16"), val = tensor<fp16, [3072, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(133808192)))];
            tensor<fp16, [3072]> model_vit_encoder_layer_9_intermediate_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_9_intermediate_dense_bias_to_fp16"), val = tensor<fp16, [3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(138526848)))];
            tensor<fp16, [1, 197, 3072]> linear_58_cast_fp16 = linear(bias = model_vit_encoder_layer_9_intermediate_dense_bias_to_fp16, weight = model_vit_encoder_layer_9_intermediate_dense_weight_to_fp16, x = input_155_cast_fp16)[name = tensor<string, []>("linear_58_cast_fp16")];
            tensor<string, []> input_159_mode_0 = const()[name = tensor<string, []>("input_159_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 197, 3072]> input_159_cast_fp16 = gelu(mode = input_159_mode_0, x = linear_58_cast_fp16)[name = tensor<string, []>("input_159_cast_fp16")];
            tensor<fp16, [768, 3072]> model_vit_encoder_layer_9_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_9_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(138533056)))];
            tensor<fp16, [768]> model_vit_encoder_layer_9_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_9_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(143251712)))];
            tensor<fp16, [1, 197, 768]> linear_59_cast_fp16 = linear(bias = model_vit_encoder_layer_9_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_9_output_dense_weight_to_fp16, x = input_159_cast_fp16)[name = tensor<string, []>("linear_59_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_163_cast_fp16 = add(x = linear_59_cast_fp16, y = input_153_cast_fp16)[name = tensor<string, []>("input_163_cast_fp16")];
            tensor<int32, [1]> hidden_states_41_axes_0 = const()[name = tensor<string, []>("hidden_states_41_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_10_layernorm_before_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_10_layernorm_before_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(143253312)))];
            tensor<fp16, [768]> model_vit_encoder_layer_10_layernorm_before_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_10_layernorm_before_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(143254912)))];
            tensor<fp16, [1, 197, 768]> hidden_states_41_cast_fp16 = layer_norm(axes = hidden_states_41_axes_0, beta = model_vit_encoder_layer_10_layernorm_before_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_10_layernorm_before_weight_to_fp16, x = input_163_cast_fp16)[name = tensor<string, []>("hidden_states_41_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_10_attention_attention_key_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_10_attention_attention_key_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(143256512)))];
            tensor<fp16, [768]> model_vit_encoder_layer_10_attention_attention_key_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_10_attention_attention_key_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(144436224)))];
            tensor<fp16, [1, 197, 768]> linear_60_cast_fp16 = linear(bias = model_vit_encoder_layer_10_attention_attention_key_bias_to_fp16, weight = model_vit_encoder_layer_10_attention_attention_key_weight_to_fp16, x = hidden_states_41_cast_fp16)[name = tensor<string, []>("linear_60_cast_fp16")];
            tensor<int32, [4]> var_696 = const()[name = tensor<string, []>("op_696"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_697_cast_fp16 = reshape(shape = var_696, x = linear_60_cast_fp16)[name = tensor<string, []>("op_697_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_10_attention_attention_value_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_10_attention_attention_value_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(144437824)))];
            tensor<fp16, [768]> model_vit_encoder_layer_10_attention_attention_value_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_10_attention_attention_value_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(145617536)))];
            tensor<fp16, [1, 197, 768]> linear_61_cast_fp16 = linear(bias = model_vit_encoder_layer_10_attention_attention_value_bias_to_fp16, weight = model_vit_encoder_layer_10_attention_attention_value_weight_to_fp16, x = hidden_states_41_cast_fp16)[name = tensor<string, []>("linear_61_cast_fp16")];
            tensor<int32, [4]> var_702 = const()[name = tensor<string, []>("op_702"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_703_cast_fp16 = reshape(shape = var_702, x = linear_61_cast_fp16)[name = tensor<string, []>("op_703_cast_fp16")];
            tensor<int32, [4]> value_21_perm_0 = const()[name = tensor<string, []>("value_21_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_10_attention_attention_query_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_10_attention_attention_query_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(145619136)))];
            tensor<fp16, [768]> model_vit_encoder_layer_10_attention_attention_query_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_10_attention_attention_query_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(146798848)))];
            tensor<fp16, [1, 197, 768]> linear_62_cast_fp16 = linear(bias = model_vit_encoder_layer_10_attention_attention_query_bias_to_fp16, weight = model_vit_encoder_layer_10_attention_attention_query_weight_to_fp16, x = hidden_states_41_cast_fp16)[name = tensor<string, []>("linear_62_cast_fp16")];
            tensor<int32, [4]> var_708 = const()[name = tensor<string, []>("op_708"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_709_cast_fp16 = reshape(shape = var_708, x = linear_62_cast_fp16)[name = tensor<string, []>("op_709_cast_fp16")];
            tensor<fp16, [1, 197, 12, 64]> mul_10_cast_fp16 = mul(x = var_709_cast_fp16, y = var_17_to_fp16)[name = tensor<string, []>("mul_10_cast_fp16")];
            tensor<bool, []> matmul_10_transpose_y_0 = const()[name = tensor<string, []>("matmul_10_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_10_transpose_x_0 = const()[name = tensor<string, []>("matmul_10_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_68_perm_0 = const()[name = tensor<string, []>("transpose_68_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_69_perm_0 = const()[name = tensor<string, []>("transpose_69_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp16, [1, 12, 197, 64]> transpose_69 = transpose(perm = transpose_69_perm_0, x = var_697_cast_fp16)[name = tensor<string, []>("transpose_77")];
            tensor<fp16, [1, 12, 197, 64]> transpose_68 = transpose(perm = transpose_68_perm_0, x = mul_10_cast_fp16)[name = tensor<string, []>("transpose_78")];
            tensor<fp16, [1, 12, 197, 197]> matmul_10_cast_fp16 = matmul(transpose_x = matmul_10_transpose_x_0, transpose_y = matmul_10_transpose_y_0, x = transpose_68, y = transpose_69)[name = tensor<string, []>("matmul_10_cast_fp16")];
            tensor<int32, []> softmax_10_axis_0 = const()[name = tensor<string, []>("softmax_10_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp16, [1, 12, 197, 197]> softmax_10_cast_fp16 = softmax(axis = softmax_10_axis_0, x = matmul_10_cast_fp16)[name = tensor<string, []>("softmax_10_cast_fp16")];
            tensor<bool, []> attn_output_21_transpose_x_0 = const()[name = tensor<string, []>("attn_output_21_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_21_transpose_y_0 = const()[name = tensor<string, []>("attn_output_21_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 12, 197, 64]> value_21_cast_fp16 = transpose(perm = value_21_perm_0, x = var_703_cast_fp16)[name = tensor<string, []>("transpose_79")];
            tensor<fp16, [1, 12, 197, 64]> attn_output_21_cast_fp16 = matmul(transpose_x = attn_output_21_transpose_x_0, transpose_y = attn_output_21_transpose_y_0, x = softmax_10_cast_fp16, y = value_21_cast_fp16)[name = tensor<string, []>("attn_output_21_cast_fp16")];
            tensor<int32, [4]> var_712_perm_0 = const()[name = tensor<string, []>("op_712_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_716 = const()[name = tensor<string, []>("op_716"), val = tensor<int32, [3]>([1, 197, 768])];
            tensor<fp16, [1, 197, 12, 64]> var_712_cast_fp16 = transpose(perm = var_712_perm_0, x = attn_output_21_cast_fp16)[name = tensor<string, []>("transpose_76")];
            tensor<fp16, [1, 197, 768]> input_165_cast_fp16 = reshape(shape = var_716, x = var_712_cast_fp16)[name = tensor<string, []>("input_165_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_10_attention_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_10_attention_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(146800448)))];
            tensor<fp16, [768]> model_vit_encoder_layer_10_attention_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_10_attention_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(147980160)))];
            tensor<fp16, [1, 197, 768]> linear_63_cast_fp16 = linear(bias = model_vit_encoder_layer_10_attention_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_10_attention_output_dense_weight_to_fp16, x = input_165_cast_fp16)[name = tensor<string, []>("linear_63_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_169_cast_fp16 = add(x = linear_63_cast_fp16, y = input_163_cast_fp16)[name = tensor<string, []>("input_169_cast_fp16")];
            tensor<int32, [1]> input_171_axes_0 = const()[name = tensor<string, []>("input_171_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_10_layernorm_after_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_10_layernorm_after_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(147981760)))];
            tensor<fp16, [768]> model_vit_encoder_layer_10_layernorm_after_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_10_layernorm_after_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(147983360)))];
            tensor<fp16, [1, 197, 768]> input_171_cast_fp16 = layer_norm(axes = input_171_axes_0, beta = model_vit_encoder_layer_10_layernorm_after_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_10_layernorm_after_weight_to_fp16, x = input_169_cast_fp16)[name = tensor<string, []>("input_171_cast_fp16")];
            tensor<fp16, [3072, 768]> model_vit_encoder_layer_10_intermediate_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_10_intermediate_dense_weight_to_fp16"), val = tensor<fp16, [3072, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(147984960)))];
            tensor<fp16, [3072]> model_vit_encoder_layer_10_intermediate_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_10_intermediate_dense_bias_to_fp16"), val = tensor<fp16, [3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(152703616)))];
            tensor<fp16, [1, 197, 3072]> linear_64_cast_fp16 = linear(bias = model_vit_encoder_layer_10_intermediate_dense_bias_to_fp16, weight = model_vit_encoder_layer_10_intermediate_dense_weight_to_fp16, x = input_171_cast_fp16)[name = tensor<string, []>("linear_64_cast_fp16")];
            tensor<string, []> input_175_mode_0 = const()[name = tensor<string, []>("input_175_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 197, 3072]> input_175_cast_fp16 = gelu(mode = input_175_mode_0, x = linear_64_cast_fp16)[name = tensor<string, []>("input_175_cast_fp16")];
            tensor<fp16, [768, 3072]> model_vit_encoder_layer_10_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_10_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(152709824)))];
            tensor<fp16, [768]> model_vit_encoder_layer_10_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_10_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(157428480)))];
            tensor<fp16, [1, 197, 768]> linear_65_cast_fp16 = linear(bias = model_vit_encoder_layer_10_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_10_output_dense_weight_to_fp16, x = input_175_cast_fp16)[name = tensor<string, []>("linear_65_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_179_cast_fp16 = add(x = linear_65_cast_fp16, y = input_169_cast_fp16)[name = tensor<string, []>("input_179_cast_fp16")];
            tensor<int32, [1]> hidden_states_45_axes_0 = const()[name = tensor<string, []>("hidden_states_45_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_11_layernorm_before_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_11_layernorm_before_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(157430080)))];
            tensor<fp16, [768]> model_vit_encoder_layer_11_layernorm_before_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_11_layernorm_before_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(157431680)))];
            tensor<fp16, [1, 197, 768]> hidden_states_45_cast_fp16 = layer_norm(axes = hidden_states_45_axes_0, beta = model_vit_encoder_layer_11_layernorm_before_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_11_layernorm_before_weight_to_fp16, x = input_179_cast_fp16)[name = tensor<string, []>("hidden_states_45_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_11_attention_attention_key_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_11_attention_attention_key_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(157433280)))];
            tensor<fp16, [768]> model_vit_encoder_layer_11_attention_attention_key_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_11_attention_attention_key_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(158612992)))];
            tensor<fp16, [1, 197, 768]> linear_66_cast_fp16 = linear(bias = model_vit_encoder_layer_11_attention_attention_key_bias_to_fp16, weight = model_vit_encoder_layer_11_attention_attention_key_weight_to_fp16, x = hidden_states_45_cast_fp16)[name = tensor<string, []>("linear_66_cast_fp16")];
            tensor<int32, [4]> var_757 = const()[name = tensor<string, []>("op_757"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_758_cast_fp16 = reshape(shape = var_757, x = linear_66_cast_fp16)[name = tensor<string, []>("op_758_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_11_attention_attention_value_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_11_attention_attention_value_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(158614592)))];
            tensor<fp16, [768]> model_vit_encoder_layer_11_attention_attention_value_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_11_attention_attention_value_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(159794304)))];
            tensor<fp16, [1, 197, 768]> linear_67_cast_fp16 = linear(bias = model_vit_encoder_layer_11_attention_attention_value_bias_to_fp16, weight = model_vit_encoder_layer_11_attention_attention_value_weight_to_fp16, x = hidden_states_45_cast_fp16)[name = tensor<string, []>("linear_67_cast_fp16")];
            tensor<int32, [4]> var_763 = const()[name = tensor<string, []>("op_763"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_764_cast_fp16 = reshape(shape = var_763, x = linear_67_cast_fp16)[name = tensor<string, []>("op_764_cast_fp16")];
            tensor<int32, [4]> value_23_perm_0 = const()[name = tensor<string, []>("value_23_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_11_attention_attention_query_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_11_attention_attention_query_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(159795904)))];
            tensor<fp16, [768]> model_vit_encoder_layer_11_attention_attention_query_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_11_attention_attention_query_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(160975616)))];
            tensor<fp16, [1, 197, 768]> linear_68_cast_fp16 = linear(bias = model_vit_encoder_layer_11_attention_attention_query_bias_to_fp16, weight = model_vit_encoder_layer_11_attention_attention_query_weight_to_fp16, x = hidden_states_45_cast_fp16)[name = tensor<string, []>("linear_68_cast_fp16")];
            tensor<int32, [4]> var_769 = const()[name = tensor<string, []>("op_769"), val = tensor<int32, [4]>([1, -1, 12, 64])];
            tensor<fp16, [1, 197, 12, 64]> var_770_cast_fp16 = reshape(shape = var_769, x = linear_68_cast_fp16)[name = tensor<string, []>("op_770_cast_fp16")];
            tensor<fp16, [1, 197, 12, 64]> mul_11_cast_fp16 = mul(x = var_770_cast_fp16, y = var_17_to_fp16)[name = tensor<string, []>("mul_11_cast_fp16")];
            tensor<bool, []> matmul_11_transpose_y_0 = const()[name = tensor<string, []>("matmul_11_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_11_transpose_x_0 = const()[name = tensor<string, []>("matmul_11_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_70_perm_0 = const()[name = tensor<string, []>("transpose_70_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_71_perm_0 = const()[name = tensor<string, []>("transpose_71_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp16, [1, 12, 197, 64]> transpose_71 = transpose(perm = transpose_71_perm_0, x = var_758_cast_fp16)[name = tensor<string, []>("transpose_73")];
            tensor<fp16, [1, 12, 197, 64]> transpose_70 = transpose(perm = transpose_70_perm_0, x = mul_11_cast_fp16)[name = tensor<string, []>("transpose_74")];
            tensor<fp16, [1, 12, 197, 197]> matmul_11_cast_fp16 = matmul(transpose_x = matmul_11_transpose_x_0, transpose_y = matmul_11_transpose_y_0, x = transpose_70, y = transpose_71)[name = tensor<string, []>("matmul_11_cast_fp16")];
            tensor<int32, []> softmax_11_axis_0 = const()[name = tensor<string, []>("softmax_11_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp16, [1, 12, 197, 197]> softmax_11_cast_fp16 = softmax(axis = softmax_11_axis_0, x = matmul_11_cast_fp16)[name = tensor<string, []>("softmax_11_cast_fp16")];
            tensor<bool, []> attn_output_transpose_x_0 = const()[name = tensor<string, []>("attn_output_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_transpose_y_0 = const()[name = tensor<string, []>("attn_output_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 12, 197, 64]> value_23_cast_fp16 = transpose(perm = value_23_perm_0, x = var_764_cast_fp16)[name = tensor<string, []>("transpose_75")];
            tensor<fp16, [1, 12, 197, 64]> attn_output_cast_fp16 = matmul(transpose_x = attn_output_transpose_x_0, transpose_y = attn_output_transpose_y_0, x = softmax_11_cast_fp16, y = value_23_cast_fp16)[name = tensor<string, []>("attn_output_cast_fp16")];
            tensor<int32, [4]> var_773_perm_0 = const()[name = tensor<string, []>("op_773_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_777 = const()[name = tensor<string, []>("op_777"), val = tensor<int32, [3]>([1, 197, 768])];
            tensor<fp16, [1, 197, 12, 64]> var_773_cast_fp16 = transpose(perm = var_773_perm_0, x = attn_output_cast_fp16)[name = tensor<string, []>("transpose_72")];
            tensor<fp16, [1, 197, 768]> input_181_cast_fp16 = reshape(shape = var_777, x = var_773_cast_fp16)[name = tensor<string, []>("input_181_cast_fp16")];
            tensor<fp16, [768, 768]> model_vit_encoder_layer_11_attention_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_11_attention_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(160977216)))];
            tensor<fp16, [768]> model_vit_encoder_layer_11_attention_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_11_attention_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(162156928)))];
            tensor<fp16, [1, 197, 768]> linear_69_cast_fp16 = linear(bias = model_vit_encoder_layer_11_attention_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_11_attention_output_dense_weight_to_fp16, x = input_181_cast_fp16)[name = tensor<string, []>("linear_69_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_185_cast_fp16 = add(x = linear_69_cast_fp16, y = input_179_cast_fp16)[name = tensor<string, []>("input_185_cast_fp16")];
            tensor<int32, [1]> input_187_axes_0 = const()[name = tensor<string, []>("input_187_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_encoder_layer_11_layernorm_after_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_11_layernorm_after_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(162158528)))];
            tensor<fp16, [768]> model_vit_encoder_layer_11_layernorm_after_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_11_layernorm_after_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(162160128)))];
            tensor<fp16, [1, 197, 768]> input_187_cast_fp16 = layer_norm(axes = input_187_axes_0, beta = model_vit_encoder_layer_11_layernorm_after_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_encoder_layer_11_layernorm_after_weight_to_fp16, x = input_185_cast_fp16)[name = tensor<string, []>("input_187_cast_fp16")];
            tensor<fp16, [3072, 768]> model_vit_encoder_layer_11_intermediate_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_11_intermediate_dense_weight_to_fp16"), val = tensor<fp16, [3072, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(162161728)))];
            tensor<fp16, [3072]> model_vit_encoder_layer_11_intermediate_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_11_intermediate_dense_bias_to_fp16"), val = tensor<fp16, [3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(166880384)))];
            tensor<fp16, [1, 197, 3072]> linear_70_cast_fp16 = linear(bias = model_vit_encoder_layer_11_intermediate_dense_bias_to_fp16, weight = model_vit_encoder_layer_11_intermediate_dense_weight_to_fp16, x = input_187_cast_fp16)[name = tensor<string, []>("linear_70_cast_fp16")];
            tensor<string, []> input_191_mode_0 = const()[name = tensor<string, []>("input_191_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp16, [1, 197, 3072]> input_191_cast_fp16 = gelu(mode = input_191_mode_0, x = linear_70_cast_fp16)[name = tensor<string, []>("input_191_cast_fp16")];
            tensor<fp16, [768, 3072]> model_vit_encoder_layer_11_output_dense_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_11_output_dense_weight_to_fp16"), val = tensor<fp16, [768, 3072]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(166886592)))];
            tensor<fp16, [768]> model_vit_encoder_layer_11_output_dense_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_encoder_layer_11_output_dense_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(171605248)))];
            tensor<fp16, [1, 197, 768]> linear_71_cast_fp16 = linear(bias = model_vit_encoder_layer_11_output_dense_bias_to_fp16, weight = model_vit_encoder_layer_11_output_dense_weight_to_fp16, x = input_191_cast_fp16)[name = tensor<string, []>("linear_71_cast_fp16")];
            tensor<fp16, [1, 197, 768]> input_195_cast_fp16 = add(x = linear_71_cast_fp16, y = input_185_cast_fp16)[name = tensor<string, []>("input_195_cast_fp16")];
            tensor<int32, [1]> sequence_output_axes_0 = const()[name = tensor<string, []>("sequence_output_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp16, [768]> model_vit_layernorm_weight_to_fp16 = const()[name = tensor<string, []>("model_vit_layernorm_weight_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(171606848)))];
            tensor<fp16, [768]> model_vit_layernorm_bias_to_fp16 = const()[name = tensor<string, []>("model_vit_layernorm_bias_to_fp16"), val = tensor<fp16, [768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(171608448)))];
            tensor<fp16, [1, 197, 768]> sequence_output_cast_fp16 = layer_norm(axes = sequence_output_axes_0, beta = model_vit_layernorm_bias_to_fp16, epsilon = var_12_to_fp16, gamma = model_vit_layernorm_weight_to_fp16, x = input_195_cast_fp16)[name = tensor<string, []>("sequence_output_cast_fp16")];
            tensor<int32, [3]> var_805_begin_0 = const()[name = tensor<string, []>("op_805_begin_0"), val = tensor<int32, [3]>([0, 0, 0])];
            tensor<int32, [3]> var_805_end_0 = const()[name = tensor<string, []>("op_805_end_0"), val = tensor<int32, [3]>([1, 1, 768])];
            tensor<bool, [3]> var_805_end_mask_0 = const()[name = tensor<string, []>("op_805_end_mask_0"), val = tensor<bool, [3]>([true, false, true])];
            tensor<bool, [3]> var_805_squeeze_mask_0 = const()[name = tensor<string, []>("op_805_squeeze_mask_0"), val = tensor<bool, [3]>([false, true, false])];
            tensor<fp16, [1, 768]> var_805_cast_fp16 = slice_by_index(begin = var_805_begin_0, end = var_805_end_0, end_mask = var_805_end_mask_0, squeeze_mask = var_805_squeeze_mask_0, x = sequence_output_cast_fp16)[name = tensor<string, []>("op_805_cast_fp16")];
            tensor<fp16, [2, 768]> model_classifier_weight_to_fp16 = const()[name = tensor<string, []>("model_classifier_weight_to_fp16"), val = tensor<fp16, [2, 768]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(171610048)))];
            tensor<fp16, [2]> model_classifier_bias_to_fp16 = const()[name = tensor<string, []>("model_classifier_bias_to_fp16"), val = tensor<fp16, [2]>([0x1.128p-12, -0x1.128p-12])];
            tensor<fp16, [1, 2]> linear_72_cast_fp16 = linear(bias = model_classifier_bias_to_fp16, weight = model_classifier_weight_to_fp16, x = var_805_cast_fp16)[name = tensor<string, []>("linear_72_cast_fp16")];
            tensor<int32, []> var_810 = const()[name = tensor<string, []>("op_810"), val = tensor<int32, []>(-1)];
            tensor<fp16, [1, 2]> var_812 = softmax(axis = var_810, x = linear_72_cast_fp16)[name = tensor<string, []>("op_812_cast_fp16")];
            tensor<string, []> var_812_cast_to_fp32_dtype_0 = const()[name = tensor<string, []>("var_812_cast_to_fp32_dtype_0"), val = tensor<string, []>("fp32")];
            tensor<fp32, [1, 2]> var_812_cast_to_fp32 = cast(dtype = var_812_cast_to_fp32_dtype_0, x = var_812)[name = tensor<string, []>("var_812_cast_to_fp32")];
        } -> (var_812_cast_to_fp32);
}